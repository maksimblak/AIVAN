"""
üéØ Cohort Analysis - Retention Dynamics

–ê–Ω–∞–ª–∏–∑ retention –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è:
- –ö–∞–∫ –º–µ–Ω—è–µ—Ç—Å—è retention —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º
- –ö–∞–∫–∏–µ –∫–æ–≥–æ—Ä—Ç—ã —Å–∞–º—ã–µ sticky
- –í–ª–∏—è–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø—Ä–æ–¥—É–∫—Ç–∞ –Ω–∞ retention
"""

import asyncio
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any
import json


@dataclass
class CohortMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ–¥–Ω–æ–π –∫–æ–≥–æ—Ä—Ç—ã"""
    cohort_month: str  # "2025-01"
    cohort_size: int  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –∫–æ–≥–æ—Ä—Ç–µ

    # Retention rates –ø–æ –¥–Ω—è–º
    day_1_retention: float  # % –≤–µ—Ä–Ω—É–≤—à–∏—Ö—Å—è –Ω–∞ –¥–µ–Ω—å 1
    day_7_retention: float
    day_30_retention: float
    day_90_retention: float

    # Revenue metrics
    paid_users: int  # –°–∫–æ–ª—å–∫–æ –∑–∞–ø–ª–∞—Ç–∏–ª–∏
    conversion_rate: float  # % –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–≤—à–∏—Ö—Å—è –≤ paid
    total_revenue: int  # –û–±—â–∏–π revenue –æ—Ç –∫–æ–≥–æ—Ä—Ç—ã
    arpu: float  # Average Revenue Per User

    # Feature adoption
    avg_features_used: float  # –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∏—á
    top_features: list[tuple[str, float]]  # [(feature, adoption_rate%)]

    # Engagement
    avg_requests_per_user: float
    avg_lifetime_days: float
    power_users_count: int  # –° power_user_score > 70

    # Churn
    churned_count: int
    churn_rate: float  # %
    avg_days_to_churn: float | None


@dataclass
class CohortComparison:
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–≥–æ—Ä—Ç –º–µ–∂–¥—É —Å–æ–±–æ–π"""
    best_cohort: str  # –ö–∞–∫–∞—è –∫–æ–≥–æ—Ä—Ç–∞ –ª—É—á—à–∞—è –ø–æ retention
    worst_cohort: str

    retention_trend: str  # "improving", "stable", "declining"
    conversion_trend: str

    key_insights: list[str]  # –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤

    # Data for visualization
    cohorts_data: list[CohortMetrics]


@dataclass
class FeatureAdoptionCohort:
    """Adoption –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ñ–∏—á–∏ –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º"""
    feature_name: str

    # Adoption timeline –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–≥–æ—Ä—Ç—ã
    cohort_adoption: dict[str, float]  # {cohort_month: adoption_rate%}

    # Time to adoption
    avg_days_to_first_use: dict[str, float]  # {cohort_month: days}

    # Retention correlation
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–≤—à–∏–µ —ç—Ç—É —Ñ–∏—á—É vs –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–≤—à–∏–µ
    users_with_feature_retention: float
    users_without_feature_retention: float
    retention_lift: float  # % —É–ª—É—á—à–µ–Ω–∏–µ retention


class CohortAnalytics:
    """
    Cohort Analysis –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è retention dynamics
    """

    def __init__(self, db):
        self.db = db

    async def get_cohort_metrics(self, cohort_month: str) -> CohortMetrics:
        """
        –ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–≥–æ—Ä—Ç—ã

        Args:
            cohort_month: "2025-01" —Ñ–æ—Ä–º–∞—Ç
        """
        async with self.db.pool.acquire() as conn:
            # Cohort size
            cursor = await conn.execute("""
                SELECT COUNT(*) as size
                FROM users
                WHERE strftime('%Y-%m', created_at, 'unixepoch') = ?
            """, (cohort_month,))
            row = await cursor.fetchone()
            await cursor.close()
            cohort_size = row[0] if row else 0

            if cohort_size == 0:
                raise ValueError(f"Cohort {cohort_month} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

            # Retention rates
            day_1 = await self._calculate_retention(conn, cohort_month, 1)
            day_7 = await self._calculate_retention(conn, cohort_month, 7)
            day_30 = await self._calculate_retention(conn, cohort_month, 30)
            day_90 = await self._calculate_retention(conn, cohort_month, 90)

            # Revenue metrics
            cursor = await conn.execute("""
                SELECT
                    COUNT(DISTINCT user_id) as paid_users,
                    COALESCE(SUM(amount), 0) as total_revenue
                FROM payments
                WHERE user_id IN (
                    SELECT user_id FROM users
                    WHERE strftime('%Y-%m', created_at, 'unixepoch') = ?
                )
                AND status = 'completed'
            """, (cohort_month,))
            row = await cursor.fetchone()
            await cursor.close()

            paid_users = row[0] if row and row[0] else 0
            total_revenue = row[1] if row and row[1] else 0
            conversion_rate = (paid_users / cohort_size * 100) if cohort_size > 0 else 0
            arpu = total_revenue / cohort_size if cohort_size > 0 else 0

            # Feature adoption
            top_features = await self._get_cohort_feature_adoption(conn, cohort_month)

            cursor = await conn.execute("""
                SELECT AVG(feature_count) as avg_features
                FROM (
                    SELECT user_id, COUNT(DISTINCT feature) as feature_count
                    FROM behavior_events
                    WHERE user_id IN (
                        SELECT user_id FROM users
                        WHERE strftime('%Y-%m', created_at, 'unixepoch') = ?
                    )
                    GROUP BY user_id
                )
            """, (cohort_month,))
            row = await cursor.fetchone()
            await cursor.close()
            avg_features_used = row[0] if row and row[0] else 0

            # Engagement
            cursor = await conn.execute("""
                SELECT
                    AVG(request_count) as avg_requests,
                    AVG(lifetime_days) as avg_lifetime
                FROM (
                    SELECT
                        u.user_id,
                        u.total_requests as request_count,
                        (strftime('%s', 'now') - u.created_at) / 86400.0 as lifetime_days
                    FROM users u
                    WHERE strftime('%Y-%m', u.created_at, 'unixepoch') = ?
                )
            """, (cohort_month,))
            row = await cursor.fetchone()
            await cursor.close()

            avg_requests = row[0] if row and row[0] else 0
            avg_lifetime = row[1] if row and row[1] else 0

            # Power users (approximation - users with high activity)
            cursor = await conn.execute("""
                SELECT COUNT(*) as power_users
                FROM users
                WHERE strftime('%Y-%m', created_at, 'unixepoch') = ?
                  AND total_requests > 50
                  AND (
                      SELECT COUNT(*) FROM payments
                      WHERE payments.user_id = users.user_id
                        AND status = 'completed'
                  ) >= 2
            """, (cohort_month,))
            row = await cursor.fetchone()
            await cursor.close()
            power_users_count = row[0] if row else 0

            # Churn metrics
            cursor = await conn.execute("""
                SELECT
                    COUNT(*) as churned,
                    AVG(days_to_churn) as avg_days_to_churn
                FROM (
                    SELECT
                        u.user_id,
                        (u.last_active - u.created_at) / 86400.0 as days_to_churn
                    FROM users u
                    WHERE strftime('%Y-%m', u.created_at, 'unixepoch') = ?
                      AND (strftime('%s', 'now') - u.last_active) > 2592000
                      AND (
                          SELECT COUNT(*) FROM payments
                          WHERE payments.user_id = u.user_id
                            AND status = 'completed'
                      ) = 1
                )
            """, (cohort_month,))
            row = await cursor.fetchone()
            await cursor.close()

            churned_count = row[0] if row and row[0] else 0
            avg_days_to_churn = row[1] if row and row[1] else None
            churn_rate = (churned_count / paid_users * 100) if paid_users > 0 else 0

            return CohortMetrics(
                cohort_month=cohort_month,
                cohort_size=cohort_size,
                day_1_retention=day_1,
                day_7_retention=day_7,
                day_30_retention=day_30,
                day_90_retention=day_90,
                paid_users=paid_users,
                conversion_rate=conversion_rate,
                total_revenue=total_revenue,
                arpu=arpu,
                avg_features_used=avg_features_used,
                top_features=top_features,
                avg_requests_per_user=avg_requests,
                avg_lifetime_days=avg_lifetime,
                power_users_count=power_users_count,
                churned_count=churned_count,
                churn_rate=churn_rate,
                avg_days_to_churn=avg_days_to_churn
            )

    async def _calculate_retention(self, conn, cohort_month: str, day_offset: int) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç–∞—Ç—å retention rate –¥–ª—è –∫–æ–≥–æ—Ä—Ç—ã –Ω–∞ day_offset

        Retention = % –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∞–∫—Ç–∏–≤–Ω—ã—Ö –Ω–∞ –¥–µ–Ω—å N –ø–æ—Å–ª–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
        """
        cursor = await conn.execute("""
            WITH cohort_users AS (
                SELECT user_id, created_at
                FROM users
                WHERE strftime('%Y-%m', created_at, 'unixepoch') = ?
            )
            SELECT
                COUNT(DISTINCT cu.user_id) as total_users,
                COUNT(DISTINCT CASE
                    WHEN EXISTS (
                        SELECT 1 FROM behavior_events be
                        WHERE be.user_id = cu.user_id
                          AND be.timestamp >= cu.created_at + (? * 86400)
                          AND be.timestamp < cu.created_at + ((? + 1) * 86400)
                    ) THEN cu.user_id
                END) as retained_users
            FROM cohort_users cu
        """, (cohort_month, day_offset, day_offset))

        row = await cursor.fetchone()
        await cursor.close()

        if not row or row[0] == 0:
            return 0.0

        total, retained = row[0], row[1]
        return (retained / total * 100) if total > 0 else 0.0

    async def _get_cohort_feature_adoption(self, conn, cohort_month: str) -> list[tuple[str, float]]:
        """–¢–æ–ø —Ñ–∏—á–∏ –∏ –∏—Ö adoption rate –≤ –∫–æ–≥–æ—Ä—Ç–µ"""
        cursor = await conn.execute("""
            WITH cohort_size AS (
                SELECT COUNT(*) as size
                FROM users
                WHERE strftime('%Y-%m', created_at, 'unixepoch') = ?
            )
            SELECT
                be.feature,
                COUNT(DISTINCT be.user_id) * 100.0 / cohort_size.size as adoption_rate
            FROM behavior_events be
            CROSS JOIN cohort_size
            WHERE be.user_id IN (
                SELECT user_id FROM users
                WHERE strftime('%Y-%m', created_at, 'unixepoch') = ?
            )
            GROUP BY be.feature, cohort_size.size
            ORDER BY adoption_rate DESC
            LIMIT 5
        """, (cohort_month, cohort_month))

        rows = await cursor.fetchall()
        await cursor.close()

        return [(row[0], row[1]) for row in rows]

    async def compare_cohorts(self, months_back: int = 6) -> CohortComparison:
        """
        –°—Ä–∞–≤–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –º–µ—Å—è—Ü–µ–≤ –∫–æ–≥–æ—Ä—Ç

        Args:
            months_back: –°–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        """
        # –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–≥–æ—Ä—Ç
        async with self.db.pool.acquire() as conn:
            cursor = await conn.execute("""
                SELECT DISTINCT strftime('%Y-%m', created_at, 'unixepoch') as cohort_month
                FROM users
                WHERE created_at > strftime('%s', 'now', ? || ' month')
                ORDER BY cohort_month DESC
            """, (f'-{months_back}',))
            rows = await cursor.fetchall()
            await cursor.close()

        cohort_months = [row[0] for row in rows if row[0]]

        if len(cohort_months) < 2:
            return CohortComparison(
                best_cohort="N/A",
                worst_cohort="N/A",
                retention_trend="insufficient_data",
                conversion_trend="insufficient_data",
                key_insights=["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–æ–≥–æ—Ä—Ç"],
                cohorts_data=[]
            )

        # –ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∫–æ–≥–æ—Ä—Ç
        cohorts_data = []
        for month in cohort_months:
            try:
                metrics = await self.get_cohort_metrics(month)
                cohorts_data.append(metrics)
            except ValueError:
                continue

        if not cohorts_data:
            return CohortComparison(
                best_cohort="N/A",
                worst_cohort="N/A",
                retention_trend="no_data",
                conversion_trend="no_data",
                key_insights=["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∫–æ–≥–æ—Ä—Ç–∞—Ö"],
                cohorts_data=[]
            )

        # –ù–∞–π—Ç–∏ –ª—É—á—à—É—é/—Ö—É–¥—à—É—é –∫–æ–≥–æ—Ä—Ç—É –ø–æ day_30_retention
        best = max(cohorts_data, key=lambda c: c.day_30_retention)
        worst = min(cohorts_data, key=lambda c: c.day_30_retention)

        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç—Ä–µ–Ω–¥—ã
        retention_trend = self._calculate_trend([c.day_30_retention for c in cohorts_data])
        conversion_trend = self._calculate_trend([c.conversion_rate for c in cohorts_data])

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
        insights = self._generate_insights(cohorts_data, best, worst)

        return CohortComparison(
            best_cohort=best.cohort_month,
            worst_cohort=worst.cohort_month,
            retention_trend=retention_trend,
            conversion_trend=conversion_trend,
            key_insights=insights,
            cohorts_data=cohorts_data
        )

    def _calculate_trend(self, values: list[float]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç—Ä–µ–Ω–¥ –ø–æ —Å–ø–∏—Å–∫—É –∑–Ω–∞—á–µ–Ω–∏–π (–æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º)"""
        if len(values) < 3:
            return "insufficient_data"

        # Linear regression slope approximation
        n = len(values)
        x_mean = (n - 1) / 2
        y_mean = sum(values) / n

        numerator = sum((i - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((i - x_mean) ** 2 for i in range(n))

        if denominator == 0:
            return "stable"

        slope = numerator / denominator

        # Classify trend
        if slope > 2:
            return "improving"
        elif slope < -2:
            return "declining"
        else:
            return "stable"

    def _generate_insights(self, cohorts: list[CohortMetrics], best: CohortMetrics, worst: CohortMetrics) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤"""
        insights = []

        # 1. Best vs Worst cohort
        retention_diff = best.day_30_retention - worst.day_30_retention
        insights.append(
            f"üìä –õ—É—á—à–∞—è –∫–æ–≥–æ—Ä—Ç–∞ ({best.cohort_month}) –∏–º–µ–µ—Ç retention –Ω–∞ {retention_diff:.1f}% "
            f"–≤—ã—à–µ —á–µ–º —Ö—É–¥—à–∞—è ({worst.cohort_month})"
        )

        # 2. Conversion trend
        avg_conversion = sum(c.conversion_rate for c in cohorts) / len(cohorts)
        latest_conversion = cohorts[0].conversion_rate if cohorts else 0

        if latest_conversion > avg_conversion * 1.1:
            insights.append(f"‚úÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –∫–æ–≥–æ—Ä—Ç–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ç—Å—è –ª—É—á—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ ({latest_conversion:.1f}% vs {avg_conversion:.1f}%)")
        elif latest_conversion < avg_conversion * 0.9:
            insights.append(f"‚ö†Ô∏è –ü–æ—Å–ª–µ–¥–Ω—è—è –∫–æ–≥–æ—Ä—Ç–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ç—Å—è —Ö—É–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ ({latest_conversion:.1f}% vs {avg_conversion:.1f}%)")

        # 3. Feature adoption comparison
        best_features = set(f[0] for f in best.top_features[:3])
        worst_features = set(f[0] for f in worst.top_features[:3])

        unique_to_best = best_features - worst_features
        if unique_to_best:
            insights.append(f"üíé –õ—É—á—à–∞—è –∫–æ–≥–æ—Ä—Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç: {', '.join(unique_to_best)}")

        # 4. Power users
        avg_power_users = sum(c.power_users_count for c in cohorts) / len(cohorts)
        if best.power_users_count > avg_power_users * 1.5:
            insights.append(f"üåü –õ—É—á—à–∞—è –∫–æ–≥–æ—Ä—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –≤ 1.5x –±–æ–ª—å—à–µ power users")

        # 5. Churn warning
        high_churn_cohorts = [c for c in cohorts if c.churn_rate > 50]
        if high_churn_cohorts:
            insights.append(f"üî¥ {len(high_churn_cohorts)} –∫–æ–≥–æ—Ä—Ç —Å churn rate > 50%")

        return insights

    async def get_feature_adoption_by_cohort(self, feature_name: str, months_back: int = 6) -> FeatureAdoptionCohort:
        """
        –ê–Ω–∞–ª–∏–∑ adoption –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ñ–∏—á–∏ –ø–æ –∫–æ–≥–æ—Ä—Ç–∞–º

        –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
        - –ö–∞–∫ –±—ã—Å—Ç—Ä–æ –∫–æ–≥–æ—Ä—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç —ç—Ç—É —Ñ–∏—á—É
        - –í–ª–∏—è–µ—Ç –ª–∏ —ç—Ç–∞ —Ñ–∏—á–∞ –Ω–∞ retention
        """
        async with self.db.pool.acquire() as conn:
            # –ü–æ–ª—É—á–∏—Ç—å –∫–æ–≥–æ—Ä—Ç—ã
            cursor = await conn.execute("""
                SELECT DISTINCT strftime('%Y-%m', created_at, 'unixepoch') as cohort_month
                FROM users
                WHERE created_at > strftime('%s', 'now', ? || ' month')
                ORDER BY cohort_month DESC
            """, (f'-{months_back}',))
            rows = await cursor.fetchall()
            await cursor.close()

            cohort_months = [row[0] for row in rows if row[0]]

            cohort_adoption = {}
            avg_days_to_first_use = {}

            for cohort_month in cohort_months:
                # Adoption rate
                cursor = await conn.execute("""
                    WITH cohort_users AS (
                        SELECT user_id FROM users
                        WHERE strftime('%Y-%m', created_at, 'unixepoch') = ?
                    )
                    SELECT
                        (SELECT COUNT(*) FROM cohort_users) as total,
                        COUNT(DISTINCT be.user_id) as adopted
                    FROM behavior_events be
                    WHERE be.feature = ?
                      AND be.user_id IN (SELECT user_id FROM cohort_users)
                """, (cohort_month, feature_name))
                row = await cursor.fetchone()
                await cursor.close()

                if row and row[0] > 0:
                    adoption_rate = (row[1] / row[0] * 100) if row[1] else 0
                    cohort_adoption[cohort_month] = adoption_rate

                # Time to first use
                cursor = await conn.execute("""
                    SELECT AVG(time_to_first_use) as avg_days
                    FROM (
                        SELECT
                            (MIN(be.timestamp) - u.created_at) / 86400.0 as time_to_first_use
                        FROM users u
                        INNER JOIN behavior_events be ON u.user_id = be.user_id
                        WHERE strftime('%Y-%m', u.created_at, 'unixepoch') = ?
                          AND be.feature = ?
                        GROUP BY u.user_id
                    )
                """, (cohort_month, feature_name))
                row = await cursor.fetchone()
                await cursor.close()

                if row and row[0] is not None:
                    avg_days_to_first_use[cohort_month] = row[0]

            # Retention correlation
            cursor = await conn.execute("""
                WITH feature_users AS (
                    SELECT DISTINCT user_id
                    FROM behavior_events
                    WHERE feature = ?
                      AND user_id IN (
                          SELECT user_id FROM users
                          WHERE created_at > strftime('%s', 'now', '-90 day')
                      )
                ),
                retention_with AS (
                    SELECT COUNT(*) as retained
                    FROM users u
                    WHERE u.user_id IN (SELECT user_id FROM feature_users)
                      AND (strftime('%s', 'now') - u.last_active) < 2592000
                ),
                retention_without AS (
                    SELECT COUNT(*) as retained
                    FROM users u
                    WHERE u.user_id NOT IN (SELECT user_id FROM feature_users)
                      AND u.created_at > strftime('%s', 'now', '-90 day')
                      AND (strftime('%s', 'now') - u.last_active) < 2592000
                ),
                total_with AS (
                    SELECT COUNT(*) as total FROM feature_users
                ),
                total_without AS (
                    SELECT COUNT(*) as total
                    FROM users
                    WHERE user_id NOT IN (SELECT user_id FROM feature_users)
                      AND created_at > strftime('%s', 'now', '-90 day')
                )
                SELECT
                    CAST(rw.retained AS REAL) / NULLIF(tw.total, 0) * 100 as retention_with,
                    CAST(rwo.retained AS REAL) / NULLIF(two.total, 0) * 100 as retention_without
                FROM retention_with rw, retention_without rwo, total_with tw, total_without two
            """, (feature_name,))
            row = await cursor.fetchone()
            await cursor.close()

            retention_with = row[0] if row and row[0] else 0
            retention_without = row[1] if row and row[1] else 0
            retention_lift = retention_with - retention_without

            return FeatureAdoptionCohort(
                feature_name=feature_name,
                cohort_adoption=cohort_adoption,
                avg_days_to_first_use=avg_days_to_first_use,
                users_with_feature_retention=retention_with,
                users_without_feature_retention=retention_without,
                retention_lift=retention_lift
            )
