# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏
"""

from __future__ import annotations

import logging
import re
from pathlib import Path
from typing import Any

from .base import DocumentProcessor, DocumentResult, ProcessingError
from .utils import FileFormatHandler, TextProcessor

logger = logging.getLogger(__name__)

# –°–ª–æ–≤–∞—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
SUPPORTED_LANGUAGES = {
    "ru": "–†—É—Å—Å–∫–∏–π",
    "en": "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π",
    "de": "–ù–µ–º–µ—Ü–∫–∏–π",
    "fr": "–§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π",
    "es": "–ò—Å–ø–∞–Ω—Å–∫–∏–π",
    "it": "–ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π",
    "pt": "–ü–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π",
    "zh": "–ö–∏—Ç–∞–π—Å–∫–∏–π",
    "ja": "–Ø–ø–æ–Ω—Å–∫–∏–π",
}

# –°–ª–æ–≤–∞—Ä—å —è–∑—ã–∫–æ–≤ —Å —Ñ–ª–∞–≥–∞–º–∏ –¥–ª—è UI
LANG_NAMES = {
    "ru": "üá∑üá∫ –†—É—Å—Å–∫–∏–π",
    "en": "üá¨üáß –ê–Ω–≥–ª–∏–π—Å–∫–∏–π",
    "de": "üá©üá™ –ù–µ–º–µ—Ü–∫–∏–π",
    "fr": "üá´üá∑ –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π",
    "es": "üá™üá∏ –ò—Å–ø–∞–Ω—Å–∫–∏–π",
    "it": "üáÆüáπ –ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π",
    "pt": "üáµüáπ –ü–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π",
    "zh": "üá®üá≥ –ö–∏—Ç–∞–π—Å–∫–∏–π",
    "ja": "üáØüáµ –Ø–ø–æ–Ω—Å–∫–∏–π",
}


def _human_lang(code: str) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —è–∑—ã–∫–∞ —Å —Ñ–ª–∞–≥–æ–º"""
    return LANG_NAMES.get(code, code)


TRANSLATION_PROMPT = """
–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ó–ê–î–ê–ß–ê: –ü–µ—Ä–µ–≤–µ–¥–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Å {source_lang} –Ω–∞ {target_lang}, —Å–æ—Ö—Ä–∞–Ω—è—è:
- –Æ—Ä–∏–¥–∏—á–µ—Å–∫—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
- –°—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
- –§–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å
- –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–æ–≤—ã—Ö –ø–æ–Ω—è—Ç–∏–π

–û–°–ù–û–í–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–Ω—è—Ç—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
- –°–æ—Ö—Ä–∞–Ω—è–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (—Å–ø–∏—Å–∫–∏, –ø—É–Ω–∫—Ç—ã, —Ç–∞–±–ª–∏—Ü—ã)
- –ê–¥–∞–ø—Ç–∏—Ä—É–π –∫ –º–µ—Å—Ç–Ω–æ–º—É –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É –≥–¥–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
- –î–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏—è –≤ —Å–∫–æ–±–∫–∞—Ö –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤

–Ø–ó–´–ö–û–í–´–ï –ü–ê–†–´:
- –†—É—Å—Å–∫–∏–π ‚Üî –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
- –†—É—Å—Å–∫–∏–π ‚Üî –ö–∏—Ç–∞–π—Å–∫–∏–π
- –†—É—Å—Å–∫–∏–π ‚Üî –ù–µ–º–µ—Ü–∫–∏–π

–ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Å–æ—Ö—Ä–∞–Ω—è—è –µ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
"""


class DocumentTranslator(DocumentProcessor):
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""

    def __init__(self, openai_service=None):
        super().__init__(name="DocumentTranslator", max_file_size=50 * 1024 * 1024)
        self.supported_formats = [".pdf", ".docx", ".doc", ".txt"]
        self.openai_service = openai_service
        self.supported_languages = SUPPORTED_LANGUAGES.copy()

    async def process(
        self, file_path: str | Path, source_lang: str = "ru", target_lang: str = "en", **kwargs
    ) -> DocumentResult:
        """
        –ü–µ—Ä–µ–≤–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞

        Args:
            file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            source_lang: –∏—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫ (ru, en, zh, de)
            target_lang: —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫ (ru, en, zh, de)
        """

        if not self.openai_service:
            raise ProcessingError(
                "OpenAI —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω", "SERVICE_ERROR"
            )

        if (
            source_lang not in self.supported_languages
            or target_lang not in self.supported_languages
        ):
            raise ProcessingError(
                "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —è–∑—ã–∫–æ–≤–∞—è –ø–∞—Ä–∞", "LANGUAGE_ERROR"
            )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞
        success, text = await FileFormatHandler.extract_text_from_file(file_path)
        if not success:
            raise ProcessingError(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç: {text}", "EXTRACTION_ERROR"
            )

        cleaned_text = TextProcessor.clean_text(text)
        if not cleaned_text.strip():
            raise ProcessingError(
                "–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞", "EMPTY_DOCUMENT"
            )

        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –¥–æ–∫—É–º–µ–Ω—Ç
        translated_text, chunk_details = await self._translate_text(
            cleaned_text, source_lang, target_lang
        )

        result_data = {
            "translated_text": translated_text,
            "source_language": source_lang,
            "target_language": target_lang,
            "original_file": str(file_path),
            "chunk_details": chunk_details,
            "translation_metadata": {
                "original_length": len(cleaned_text),
                "translated_length": len(translated_text),
                "language_pair": f"{source_lang} -> {target_lang}",
                "chunks_processed": len(chunk_details),
            },
        }

        return DocumentResult.success_result(
            data=result_data,
            message=f"–ü–µ—Ä–µ–≤–æ–¥ —Å {self.supported_languages[source_lang]} –Ω–∞ {self.supported_languages[target_lang]} –∑–∞–≤–µ—Ä—à–µ–Ω",
        )

    async def _translate_text(
        self, text: str, source_lang: str, target_lang: str
    ) -> tuple[str, list[dict[str, Any]]]:
        """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é AI"""

        source_lang_name = self.supported_languages[source_lang]
        target_lang_name = self.supported_languages[target_lang]

        prompt = TRANSLATION_PROMPT.format(
            source_lang=source_lang_name, target_lang=target_lang_name
        )
        chunk_details: list[dict[str, Any]] = []

        try:
            if len(text) > 6000:
                chunks = TextProcessor.split_into_chunks(text, max_chunk_size=4000)
                translated_chunks: list[str] = []

                for i, chunk in enumerate(chunks):
                    logger.info(f"–ü–µ—Ä–µ–≤–æ–¥–∏–º —á–∞—Å—Ç—å {i+1}/{len(chunks)}")

                    chunk_prompt = (
                        f"–ß–∞—Å—Ç—å {i + 1} –∏–∑ {len(chunks)} –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞.\n"
                        "–°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Å–ø–∏—Å–∫–∏, —Ç–∞–±–ª–∏—Ü—ã –∏ –Ω—É–º–µ—Ä–∞—Ü–∏—é.\n\n"
                        f"{chunk}"
                    )

                    result = await self.openai_service.ask_legal(
                        system_prompt=prompt, user_text=chunk_prompt
                    )

                    if result.get("ok"):
                        translated_part = result.get("text", "")
                        translated_chunks.append(translated_part)
                        chunk_details.append(
                            {
                                "chunk_number": i + 1,
                                "source_preview": chunk[:200],
                                "translated_preview": translated_part[:200],
                            }
                        )
                    else:
                        raise ProcessingError(
                            f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —á–∞—Å—Ç–∏ {i + 1}", "TRANSLATION_ERROR"
                        )

                return "\n\n".join(translated_chunks), chunk_details

            result = await self.openai_service.ask_legal(system_prompt=prompt, user_text=text)

            if result.get("ok"):
                translated_text = result.get("text", "")
                chunk_details.append(
                    {
                        "chunk_number": 1,
                        "source_preview": text[:200],
                        "translated_preview": translated_text[:200],
                    }
                )
                return translated_text, chunk_details

            raise ProcessingError(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç", "TRANSLATION_ERROR"
            )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
            raise ProcessingError(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {str(e)}", "TRANSLATION_ERROR")

    def get_supported_languages(self) -> dict[str, str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤"""
        return self.supported_languages.copy()

    def detect_language(self, text: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        # –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ - –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
        if re.search(r"[–∞-—è—ë]", text.lower()):
            return "ru"
        elif re.search(r"[\u4e00-\u9fff]", text):
            return "zh"
        elif re.search(r"[√§√∂√º√ü]", text.lower()):
            return "de"
        else:
            return "en"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é