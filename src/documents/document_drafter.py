"""Utilities for interactive legal document drafting."""

from __future__ import annotations

import json
import logging
import re
from contextlib import suppress
from dataclasses import dataclass
from typing import Any, Iterable

logger = logging.getLogger(__name__)


class DocumentDraftingError(RuntimeError):
    """Raised when the LLM response cannot be processed."""


@dataclass(slots=True)
class DraftPlan:
    title: str
    questions: list[dict[str, str]]
    notes: list[str]


@dataclass(slots=True)
class DraftResult:
    status: str
    title: str
    markdown: str
    validated: list[str]
    issues: list[str]
    follow_up_questions: list[str]


DOCUMENT_PLANNER_SYSTEM_PROMPT = """
Ğ¢Ñ‹ â€” ÑÑ€Ğ¸Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ ÑÑ€Ğ¸ÑÑ‚Ñƒ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ°Ğ²Ğ¾Ğ²Ğ¾Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ¿Ğ¾Ğ´ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğµ Ğ´ĞµĞ»Ğ¾.
Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ ÑÑ‚Ğ°Ğ¿Ğ°Ğ¼:

1. Ğ•ÑĞ»Ğ¸ ÑÑ€Ğ¸ÑÑ‚ ÑƒĞ¶Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ» Ñ‚Ğ¸Ğ¿ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ° â€” Ğ½Ğ°Ğ¹Ğ´Ğ¸ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰Ğ¸Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ·ĞµÑ† Ğ¸ ÑÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒĞ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°. Ğ•ÑĞ»Ğ¸ Ñ‚Ğ¸Ğ¿ Ğ½Ğµ Ğ¾Ñ‡ĞµĞ²Ğ¸Ğ´ĞµĞ½, Ğ·Ğ°Ğ´Ğ°Ğ¹ Ğ½Ğ°Ğ²Ğ¾Ğ´ÑÑ‰Ğ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ, ĞºĞ°ĞºĞ¾Ğ¹ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ½ÑƒĞ¶ĞµĞ½.
2. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ÑŒ Ğ¿ĞµÑ€ĞµÑ‡ĞµĞ½ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‚ÑŒ ÑÑ€Ğ¸ÑÑ‚Ñƒ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°. ĞŸÑ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞ¹ Ğ¸Ñ… Ğ¿Ğ¾ ÑÑ‚Ğ°Ğ¿Ğ°Ğ¼ Ğ¸ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾ÑÑĞ½ÑĞ¹ Ñ†ĞµĞ»ÑŒ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°.
3. Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞ¹ Ğ·Ğ°Ğ¼ĞµÑ‚ĞºĞ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° (context_notes), ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ³Ğ¾Ğ´ÑÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¸ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ˜Ğ˜ Ğ¿Ñ€Ğ¸Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒÑÑ ÑÑ€Ğ¸Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸.

Ğ’ÑĞµĞ³Ğ´Ğ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°Ğ¹ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON.
""".strip()

DOCUMENT_PLANNER_USER_TEMPLATE = """
Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ ÑÑ€Ğ¸ÑÑ‚Ğ°:
{request}

Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°:
- ĞŸĞ¾Ğ»Ğµ document_title â€” Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°.
- ĞŸĞ¾Ğ»Ğµ need_more_info = true, ĞµÑĞ»Ğ¸ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ÑÑ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ ÑÑ€Ğ¸ÑÑ‚Ğ°; false, ĞµÑĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸.
- ĞœĞ°ÑÑĞ¸Ğ² questions: ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹ {{"id": "...", "text": "...", "purpose": "..."}} Ñ Ğ¿Ğ¾ÑÑĞ½ĞµĞ½Ğ¸ĞµĞ¼ Ñ†ĞµĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°.
- ĞœĞ°ÑÑĞ¸Ğ² context_notes: ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ğ·Ğ°Ğ¼ĞµÑ‚ĞºĞ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°.

ĞÑ‚Ğ²ĞµÑ‚ Ğ²ĞµÑ€Ğ½Ğ¸ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ² JSON.
""".strip()

DOCUMENT_GENERATOR_SYSTEM_PROMPT = """
Ğ¢Ñ‹ â€” ÑÑ€Ğ¸Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚-Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ»Ğ¸ÑÑ‚. ĞĞ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² ÑÑ€Ğ¸ÑÑ‚Ğ° Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ÑŒ ÑÑ€Ğ¸Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚.
Ğ¡Ğ»ĞµĞ´ÑƒĞ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸:

1. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ, Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ•ÑĞ»Ğ¸ Ñ‡ĞµĞ³Ğ¾-Ñ‚Ğ¾ Ğ½Ğµ Ñ…Ğ²Ğ°Ñ‚Ğ°ĞµÑ‚, Ğ²ĞµÑ€Ğ½Ğ¸ status = "need_more_info" Ğ¸ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞ¹ follow_up_questions Ñ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸ÑĞ¼Ğ¸.
2. Ğ•ÑĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾, ÑĞ¾ÑÑ‚Ğ°Ğ²ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ² Markdown, Ğ¾Ğ¿Ğ¸Ñ€Ğ°ÑÑÑŒ Ğ½Ğ° Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ·ĞµÑ† Ğ¸ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ñ‹. Ğ¡Ğ¾Ğ±Ğ»ÑĞ´Ğ°Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ, ÑÑ‚Ğ¸Ğ»ÑŒ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸, Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ²Ğ¸Ğ´Ğ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°.
3. Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° `document_markdown`:
   â€¢ Ğ’ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑÑ‚Ğ¸ Ğ±Ğ»Ğ¾Ğº Ñ€ĞµĞºĞ²Ğ¸Ğ·Ğ¸Ñ‚Ğ¾Ğ² ÑÑ‚Ñ€Ğ¾ĞºĞ°Ğ¼Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° `ĞŸĞ¾Ğ»Ğµ: Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ` (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: `Ğ¡ÑƒĞ´: ...`, `Ğ˜ÑÑ‚ĞµÑ†: ...`, `ĞÑ‚Ğ²ĞµÑ‚Ñ‡Ğ¸Ğº: ...`, `Ğ¦ĞµĞ½Ğ° Ğ¸ÑĞºĞ°: ...`, `Ğ“Ğ¾ÑĞ¿Ğ¾ÑˆĞ»Ğ¸Ğ½Ğ°: ...`, Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ â€” `Ğ”Ğ°Ñ‚Ğ°: ...`, `ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑÑŒ: ...`). ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¿ÑĞµĞ²Ğ´Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºÑƒ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğµ ÑĞ»ÑÑˆĞ¸ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ½Ğ¾ÑĞ¾Ğ².
   â€¢ ĞŸĞ¾ÑĞ»Ğµ Ñ€ĞµĞºĞ²Ğ¸Ğ·Ğ¸Ñ‚Ğ¾Ğ² ÑĞ´ĞµĞ»Ğ°Ğ¹ Ğ¿ÑƒÑÑ‚ÑƒÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· `# {Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ}`.
   â€¢ ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ñ‹ Ğ¾Ñ„Ğ¾Ñ€Ğ¼Ğ»ÑĞ¹ Ğ¿Ğ¾Ğ´Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°Ğ¼Ğ¸ `## â€¦`, Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¾Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¿Ñ€Ğ¾Ğ½ÑƒĞ¼ĞµÑ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¿Ğ¸ÑĞºĞ¸ `1.` Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ² Ğ¸ Ğ¼Ğ°Ñ€ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¿Ğ¸ÑĞºĞ¸ `-` Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ².
   â€¢ Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸ (Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ‡Ğ°ÑÑ‚ÑŒ, Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ, Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ) Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ´Ğ°Ğ¹ Ğ² Ğ²Ğ¸Ğ´Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¿Ğ¸ÑĞºĞ¾Ğ², Ğ±ĞµĞ· `\` Ğ² ĞºĞ¾Ğ½Ñ†Ğµ ÑÑ‚Ñ€Ğ¾Ğº.
4. ĞŸĞµÑ€ĞµĞ´ Ğ²Ñ‹Ğ´Ğ°Ñ‡ĞµĞ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸ ÑĞ°Ğ¼Ğ¾Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºÑƒ: Ğ¿ĞµÑ€ĞµÑ‡Ğ¸ÑĞ»Ğ¸ ÑƒÑ‡Ñ‚Ñ‘Ğ½Ğ½Ñ‹Ğµ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ğ²Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ñ€Ğ¸ÑĞºĞ¸/Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹.

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° â€” Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON Ğ²Ğ¸Ğ´Ğ°:
{
  "status": "ok" | "need_more_info" | "abort",
  "document_title": "...",
  "document_markdown": "...",
  "self_check": {
    "validated": ["..."],
    "issues": ["..."]
  },
  "follow_up_questions": ["..."]
}
Ğ•ÑĞ»Ğ¸ status = "ok", Ğ¿Ğ¾Ğ»Ğµ document_markdown Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚, Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğº ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ² Word.
""".strip()

DOCUMENT_GENERATOR_USER_TEMPLATE = """
Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ ÑÑ€Ğ¸ÑÑ‚Ğ° Ğ¸ Ğ²Ğ²Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:
{request}

ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ğ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°: {title}

ĞÑ‚Ğ²ĞµÑ‚Ñ‹ ÑÑ€Ğ¸ÑÑ‚Ğ°:
{answers}

Ğ¡Ğ¾Ğ±ĞµÑ€Ğ¸ Ğ¸Ñ‚Ğ¾Ğ³ Ğ¿Ğ¾ ÑÑ…ĞµĞ¼Ğµ JSON:
{{
  "status": "ok" | "need_more_info" | "abort",
  "document_title": "...",
  "document_markdown": "...",
  "self_check": {{
    "validated": ["..."],
    "issues": ["..."]
  }},
  "follow_up_questions": ["..."]
}}
""".strip()

_JSON_START_RE = re.compile(r"[{\[]")
_TRAILING_COMMA_RE = re.compile(r",(\s*[}\]])")
_JSON_DECODER = json.JSONDecoder()


def _strip_code_fences(payload: str) -> str:
    stripped = payload.strip()
    lowered = stripped.lower()
    for prefix in ("```json", "```", "~~~json", "~~~"):
        if lowered.startswith(prefix):
            stripped = stripped[len(prefix) :]
            stripped = stripped.lstrip("\r\n")
            break

    for suffix in ("```", "~~~"):
        if stripped.endswith(suffix):
            stripped = stripped[: -len(suffix)]
            stripped = stripped.rstrip()
            break

    return stripped.strip()


def _extract_json(text: Any) -> Any:
    """Extract the first JSON structure found in text."""

    if isinstance(text, (dict, list)):
        return text
    if text is None:
        raise DocumentDraftingError("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ JSON Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
    if not isinstance(text, str):
        raise DocumentDraftingError("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ JSON Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

    cleaned_text = _strip_code_fences(text)

    def _try_parse(candidate: str) -> Any:
        candidate = candidate.strip()
        if not candidate:
            raise json.JSONDecodeError("Empty JSON candidate", candidate, 0)
        normalized = _TRAILING_COMMA_RE.sub(r"\1", candidate)
        obj, _ = _JSON_DECODER.raw_decode(normalized)
        return obj

    try:
        return _try_parse(cleaned_text)
    except (json.JSONDecodeError, ValueError) as err:
        logger.debug("Primary JSON parse failed, scanning for nested JSON: %s", err)
        for match in _JSON_START_RE.finditer(cleaned_text):
            start_idx = match.start()
            try:
                return _try_parse(cleaned_text[start_idx:])
            except (json.JSONDecodeError, ValueError):
                continue

    raise DocumentDraftingError("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ JSON Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")


def _format_answers(answers: Iterable[dict[str, str]]) -> str:
    lines = []
    for idx, item in enumerate(answers, 1):
        question = item.get("question", "").strip()
        answer = item.get("answer", "").strip()
        lines.append(f"{idx}. {question}\n   ĞÑ‚Ğ²ĞµÑ‚: {answer}")
    return "\n".join(lines) if lines else "(ĞÑ‚Ğ²ĞµÑ‚Ñ‹ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ñ‹)"



async def plan_document(openai_service, request_text: str) -> DraftPlan:
    if not request_text.strip():
        raise DocumentDraftingError("ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ")

    user_prompt = DOCUMENT_PLANNER_USER_TEMPLATE.format(request=request_text.strip())
    response = await openai_service.ask_legal(
        system_prompt=DOCUMENT_PLANNER_SYSTEM_PROMPT,
        user_text=user_prompt,
    )
    if not response.get("ok"):
        raise DocumentDraftingError(response.get("error") or "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

    raw_text = response.get("text", "")
    if not raw_text:
        raise DocumentDraftingError("ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

    data = _extract_json(raw_text)
    title = str(data.get("document_title") or "Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚").strip()
    questions = [
        {
            "id": str(q.get("id") or f"q{i+1}"),
            "text": str(q.get("text") or "").strip(),
            "purpose": str(q.get("purpose") or "").strip(),
        }
        for i, q in enumerate(data.get("questions") or [])
        if str(q.get("text") or "").strip()
    ]
    notes = [str(note).strip() for note in data.get("context_notes") or [] if str(note).strip()]

    need_more_raw = data.get("need_more_info")
    if isinstance(need_more_raw, bool):
        need_more = need_more_raw
    elif isinstance(need_more_raw, str):
        lowered = need_more_raw.strip().lower()
        need_more = lowered in {"true", "yes", "1", "y"}
    elif need_more_raw is None:
        need_more = False
    else:
        need_more = bool(need_more_raw)
    if not need_more:
        questions = []

    return DraftPlan(title=title or "Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚", questions=questions, notes=notes)


async def generate_document(
    openai_service,
    request_text: str,
    title: str,
    answers: list[dict[str, str]],
) -> DraftResult:
    answers_formatted = _format_answers(answers)
    user_prompt = DOCUMENT_GENERATOR_USER_TEMPLATE.format(
        request=request_text.strip(),
        title=title,
        answers=answers_formatted or "(ĞÑ‚Ğ²ĞµÑ‚Ñ‹ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ñ‹)",
    )
    response = await openai_service.ask_legal(
        system_prompt=DOCUMENT_GENERATOR_SYSTEM_PROMPT,
        user_text=user_prompt,
    )
    if not response.get("ok"):
        raise DocumentDraftingError(response.get("error") or "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

    raw_text = response.get("text", "")
    if not raw_text:
        raise DocumentDraftingError("ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")

    data = _extract_json(raw_text)
    status = str(data.get("status") or "ok").lower()
    doc_title = str(data.get("document_title") or title).strip()
    markdown = str(data.get("document_markdown") or "")
    self_check = data.get("self_check") or {}
    validated = [str(item).strip() for item in self_check.get("validated") or [] if str(item).strip()]
    issues = [str(item).strip() for item in self_check.get("issues") or [] if str(item).strip()]
    follow_up = [str(item).strip() for item in data.get("follow_up_questions") or [] if str(item).strip()]

    return DraftResult(
        status=status,
        title=doc_title or title,
        markdown=markdown,
        validated=validated,
        issues=issues,
        follow_up_questions=follow_up,
    )


def build_docx_from_markdown(markdown: str, output_path: str) -> None:
    try:
        from docx import Document  # type: ignore
        from docx.enum.text import WD_ALIGN_PARAGRAPH  # type: ignore
        from docx.oxml.ns import qn  # type: ignore
        from docx.shared import Cm, Pt  # type: ignore
    except ImportError as exc:  # pragma: no cover
        raise DocumentDraftingError("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ñ‚ÑŒ DOCX Ğ±ĞµĞ· Ğ¿Ğ°ĞºĞµÑ‚Ğ° python-docx") from exc

    if not markdown.strip():
        raise DocumentDraftingError("ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°")

    document = Document()
    section = document.sections[0]
    for attr in ("top_margin", "bottom_margin", "left_margin", "right_margin"):
        setattr(section, attr, Cm(2.5))

    def _ensure_font(style_name: str, *, size: int, bold: bool = False, italic: bool = False, align: int | None = None) -> None:
        try:
            style = document.styles[style_name]
        except KeyError:
            return
        font = style.font
        font.name = "Times New Roman"
        font.size = Pt(size)
        font.bold = bold
        font.italic = italic
        if style.element.rPr is not None:
            r_fonts = style.element.rPr.rFonts
            if r_fonts is not None:
                r_fonts.set(qn("w:eastAsia"), "Times New Roman")
        paragraph_format = getattr(style, "paragraph_format", None)
        if paragraph_format:
            paragraph_format.space_after = Pt(6)
            if align is not None:
                paragraph_format.alignment = align

    normal_style = document.styles["Normal"]
    normal_font = normal_style.font
    normal_font.name = "Times New Roman"
    normal_font.size = Pt(12)
    if normal_style.element.rPr is not None:
        r_fonts = normal_style.element.rPr.rFonts
        if r_fonts is not None:
            r_fonts.set(qn("w:eastAsia"), "Times New Roman")
    normal_paragraph = normal_style.paragraph_format
    normal_paragraph.space_after = Pt(6)
    normal_paragraph.first_line_indent = Cm(0)
    normal_paragraph.line_spacing = 1.5

    _ensure_font("Title", size=16, bold=True, align=WD_ALIGN_PARAGRAPH.CENTER)
    _ensure_font("Heading 1", size=14, bold=True)
    _ensure_font("Heading 2", size=13, bold=True)
    _ensure_font("Heading 3", size=12, bold=True)

    def _add_runs(paragraph, text: str) -> None:
        pattern = re.compile(r"(\*\*.+?\*\*|__.+?__|\*.+?\*|_.+?_|`.+?`)", re.DOTALL)
        for chunk in pattern.split(text):
            if not chunk:
                continue
            run = paragraph.add_run()
            if chunk.startswith(("**", "__")) and chunk.endswith(chunk[:2]):
                run.text = chunk[2:-2]
                run.bold = True
            elif chunk.startswith(("*", "_")) and chunk.endswith(chunk[0]):
                run.text = chunk[1:-1]
                run.italic = True
            elif chunk.startswith("`") and chunk.endswith("`"):
                run.text = chunk[1:-1]
                run.font.name = "Consolas"
                run.font.size = Pt(11)
            else:
                run.text = chunk

    list_mode: str | None = None
    metadata_buffer: list[tuple[str, str]] = []

    def flush_metadata(force_plain: bool = False) -> None:
        nonlocal metadata_buffer
        if not metadata_buffer:
            return

        if not force_plain and len(metadata_buffer) >= 2:
            table = document.add_table(rows=0, cols=2)
            with suppress(Exception):
                table.style = "Table Grid"
            for field, value in metadata_buffer:
                row = table.add_row()
                field_cell, value_cell = row.cells

                field_paragraph = field_cell.paragraphs[0]
                field_paragraph.paragraph_format.space_before = Pt(0)
                field_paragraph.paragraph_format.space_after = Pt(0)
                field_paragraph.paragraph_format.first_line_indent = Cm(0)
                field_paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                field_run = field_paragraph.add_run(field)
                field_run.bold = True

                value_paragraph = value_cell.paragraphs[0]
                value_paragraph.paragraph_format.space_before = Pt(0)
                value_paragraph.paragraph_format.space_after = Pt(0)
                value_paragraph.paragraph_format.first_line_indent = Cm(0)
                value_paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                _add_runs(value_paragraph, value)

            document.add_paragraph("")
        else:
            for field, value in metadata_buffer:
                paragraph = document.add_paragraph(style="Normal")
                paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                paragraph.paragraph_format.first_line_indent = Cm(0)
                paragraph.paragraph_format.left_indent = Cm(0)
                paragraph.paragraph_format.space_after = Pt(6)
                _add_runs(paragraph, f"{field}: {value}")

        metadata_buffer = []

    for raw_line in markdown.replace("\r\n", "\n").replace("\r", "\n").splitlines():
        line = raw_line.rstrip()

        if line.endswith("\\"):
            line = line[:-1].rstrip()

        if not line:
            flush_metadata()
            document.add_paragraph("")
            list_mode = None
            continue

        plain_line = line.strip()
        if plain_line and plain_line.lower().startswith("Ğ¸ÑĞºĞ¾Ğ²Ğ¾Ğµ Ğ·Ğ°ÑĞ²Ğ»ĞµĞ½Ğ¸Ğµ"):
            title_paragraph = document.add_paragraph(style="Title")
            title_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            title_paragraph.paragraph_format.space_before = Pt(12)
            title_paragraph.paragraph_format.space_after = Pt(12)
            title_paragraph.paragraph_format.keep_with_next = True
            _add_runs(title_paragraph, plain_line)
            list_mode = None
            continue

        colon_match = None
        if list_mode is None and plain_line:
            if (
                not plain_line.startswith(("-", "*", "â€¢", "#"))
                and not re.match(r"^\d+[.)]", plain_line)
            ):
                colon_match = re.match(r"^([^:]{1,80}):\s+(.+)$", plain_line)
        if colon_match:
            field = colon_match.group(1).strip()
            value = colon_match.group(2).strip()
            if value:
                metadata_buffer.append((field, value))
                continue

        flush_metadata()

        if line.startswith("# "):
            content = line[2:].strip()
            title_paragraph = document.add_paragraph(style="Title")
            title_paragraph.paragraph_format.space_after = Pt(12)
            title_paragraph.paragraph_format.keep_with_next = True
            title_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            _add_runs(title_paragraph, content.upper())
            list_mode = None
            continue

        if line.startswith("## "):
            content = line[3:].strip()
            paragraph = document.add_paragraph(style="Heading 1")
            paragraph.paragraph_format.keep_with_next = True
            paragraph.paragraph_format.space_before = Pt(12)
            _add_runs(paragraph, content)
            list_mode = None
            continue

        if line.startswith("### "):
            content = line[4:].strip()
            paragraph = document.add_paragraph(style="Heading 2")
            paragraph.paragraph_format.keep_with_next = True
            paragraph.paragraph_format.space_before = Pt(10)
            _add_runs(paragraph, content)
            list_mode = None
            continue

        bullet_match = re.match(r"^([-*â€¢])\s+(.*)", line)
        number_match = re.match(r"^\d+[.)]\s+(.*)", line)
        if bullet_match:
            paragraph = document.add_paragraph(style="List Bullet")
            paragraph.paragraph_format.first_line_indent = Pt(0)
            paragraph.paragraph_format.left_indent = Cm(0.75)
            _add_runs(paragraph, bullet_match.group(2).strip())
            list_mode = "bullet"
            continue
        if number_match:
            paragraph = document.add_paragraph(style="List Number")
            paragraph.paragraph_format.first_line_indent = Pt(0)
            paragraph.paragraph_format.left_indent = Cm(0.75)
            _add_runs(paragraph, number_match.group(1).strip())
            list_mode = "number"
            continue

        paragraph = document.add_paragraph(style="Normal")
        paragraph.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
        paragraph.paragraph_format.space_after = Pt(6)
        if list_mode:
            paragraph.paragraph_format.left_indent = Cm(1.25)
            paragraph.paragraph_format.first_line_indent = Cm(0)
        else:
            plain_line = line.strip()
            if ":" in plain_line and not plain_line.endswith(":"):
                paragraph.paragraph_format.first_line_indent = Cm(0)
                paragraph.paragraph_format.left_indent = Cm(0)
                paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
            else:
                paragraph.paragraph_format.first_line_indent = Cm(1.25)
        _add_runs(paragraph, line.strip())
        list_mode = None

    flush_metadata()

    document.save(output_path)


def _pluralize_questions(count: int) -> str:
    """Ğ¡ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ° 'Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ' Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ‡Ğ¸ÑĞ»Ğ°."""
    if count % 10 == 1 and count % 100 != 11:
        return "Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ"
    elif count % 10 in (2, 3, 4) and count % 100 not in (12, 13, 14):
        return "Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°"
    else:
        return "Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²"


def format_plan_summary(plan: DraftPlan) -> str:
    from html import escape as html_escape

    lines: list[str] = []

    title = (plan.title or "Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚").strip()
    title_escaped = html_escape(title)

    # ĞšÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“")
    lines.append("â”ƒ  ğŸ“‹ <b>ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°</b>   â”ƒ")
    lines.append("â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›")
    lines.append("")
    lines.append(f"<b>Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚:</b> {title_escaped}")
    lines.append("")

    if plan.questions:
        lines.append(f"<b>Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ:</b> {len(plan.questions)} {_pluralize_questions(len(plan.questions))}")
        lines.append("")
        lines.append("")
        lines.append("ğŸ’¡ <b>Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñƒ</b>")
        lines.append("")
        lines.append("<b>ĞšĞ°Ğº Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ñ‚ÑŒ:</b>")
        lines.append("")
        lines.append("  âœ“ ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ğ²ÑĞµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼")
        lines.append("    ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¸, Ğ½Ğµ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑÑ Ğ¸Ñ…")
        lines.append("")
        lines.append("<b>Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²:</b>")
        lines.append("")
        lines.append("  <b>Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1</b> â€” Ğ½ÑƒĞ¼ĞµÑ€Ğ°Ñ†Ğ¸Ñ:")
        lines.append("  <code>1) Ğ’Ğ°Ñˆ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚</code>")
        lines.append("  <code>2) Ğ’Ğ°Ñˆ Ğ²Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚</code>")
        lines.append("  <code>3) Ğ’Ğ°Ñˆ Ñ‚Ñ€ĞµÑ‚Ğ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚</code>")
        lines.append("")
        lines.append("  <b>Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2</b> â€” Ğ¿ÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°:")
        lines.append("  <code>ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚</code>")
        lines.append("  <code></code>")
        lines.append("  <code>Ğ’Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚</code>")
        lines.append("")
        lines.append("")
        lines.append("ğŸ‘‡ <i>Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¼</i>")
        lines.append("   <i>ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸ĞµĞ¼ Ğ½Ğ¸Ğ¶Ğµ</i>")
    else:
        lines.append("<b>Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:</b> Ğ“Ğ¾Ñ‚Ğ¾Ğ² Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ âœ…")
        lines.append("")
        lines.append("")
        lines.append("âœ… <b>Ğ’ÑÑ‘ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!</b>")
        lines.append("")
        lines.append("Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ")
        lines.append("Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ.")
        lines.append("")
        lines.append("ğŸš€ ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ÑÑ‚ÑƒĞ¿Ğ°Ñ‚ÑŒ Ğº")
        lines.append("   Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°")

    return "\n".join(lines)
