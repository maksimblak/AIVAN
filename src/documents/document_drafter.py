"""Utilities for interactive legal document drafting."""

from __future__ import annotations

import json
import logging
import re
from contextlib import suppress
from dataclasses import dataclass
from typing import Any, Iterable, Mapping

logger = logging.getLogger(__name__)


# ============================== Errors & Models ===============================

class DocumentDraftingError(RuntimeError):
    """Raised when the LLM response cannot be processed."""


@dataclass(slots=True)
class DraftPlan:
    title: str
    questions: list[dict[str, str]]
    notes: list[str]


@dataclass(slots=True)
class DraftResult:
    status: str
    title: str
    markdown: str
    validated: list[str]
    issues: list[str]
    follow_up_questions: list[str]


# ============================ System & User Prompts ===========================

DOCUMENT_ASSISTANT_SYSTEM_PROMPT = """
–¢—ã ‚Äî —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —é—Ä–∏—Å—Ç—É –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∏ –æ—Ñ–æ—Ä–º–∏—Ç—å –ø—Ä–∞–≤–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–µ–ª–æ. –†–∞–±–æ—Ç–∞–µ—à—å –≤ –¥–≤—É—Ö —Ä–µ–∂–∏–º–∞—Ö, —Ä–µ–∂–∏–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–æ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.

–û–±—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞:
- –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π –≤–∞–ª–∏–¥–Ω—ã–π JSON –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è–π —Ç–µ–∫—Å—Ç –≤–Ω–µ JSON. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏ (```), –ø—Å–µ–≤–¥–æ–≥—Ä–∞—Ñ–∏–∫—É, backslashes –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
- –°–æ–±–ª—é–¥–∞–π —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∏ –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ.
- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∑–∞–ø—Ä–æ—Å–∏ —É—Ç–æ—á–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ follow_up_questions –∏–ª–∏ –≤–æ–ø—Ä–æ—Å—ã.

–†–µ–∂–∏–º ¬´–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ¬ª (–∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤—Ä–æ–¥–µ ¬´–°—Ñ–æ—Ä–º–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞¬ª, ¬´–ü–æ–ª–µ document_title‚Ä¶¬ª):
1. –ï—Å–ª–∏ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ–Ω—è—Ç–µ–Ω ‚Äî –Ω–∞–π–¥–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –æ–±—Ä–∞–∑–µ—Ü –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ï—Å–ª–∏ —Ç–∏–ø –Ω–µ–æ—á–µ–≤–∏–¥–µ–Ω, –ø—Ä–µ–¥–ª–æ–∂–∏ —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã.
2. –ü–æ–¥–≥–æ—Ç–æ–≤—å –ø–µ—Ä–µ—á–µ–Ω—å –≤–æ–ø—Ä–æ—Å–æ–≤, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —é—Ä–∏—Å—Ç—É –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞; –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≥—Ä—É–ø–ø–∏—Ä—É–π –∏ –ø–æ—è—Å–Ω—è–π —Ü–µ–ª—å –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.
3. –°—Ñ–æ—Ä–º–∏—Ä—É–π –∑–∞–º–µ—Ç–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (context_notes), –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≥–æ–¥—è—Ç—Å—è –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –ø–æ–º–æ–≥—É—Ç —Å–æ–±–ª—é–¥–∞—Ç—å —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å.

–†–µ–∂–∏–º ¬´–ì–µ–Ω–µ—Ä–∞—Ü–∏—è¬ª (–∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤–µ—Ä–Ω—É—Ç—å status/document_markdown/self_check –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞):
1. –ü—Ä–æ–≤–µ—Ä—å –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö. –ï—Å–ª–∏ —Å–≤–µ–¥–µ–Ω–∏–π –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –≤–µ—Ä–Ω–∏ status = "need_more_info" –∏ —Å—Ñ–æ—Ä–º–∏—Ä—É–π follow_up_questions —Å —É—Ç–æ—á–Ω–µ–Ω–∏—è–º–∏.
2. –ü—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ Markdown, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –æ–±—Ä–∞–∑—Ü—ã –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã, —Å–æ–±–ª—é–¥–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Å—Ç–∏–ª—å –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –≤–∏–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
3. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ `document_markdown`:
   ‚Ä¢ –í –Ω–∞—á–∞–ª–µ —Ä–∞–∑–º–µ—Å—Ç–∏ –±–ª–æ–∫ —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤ —Å—Ç—Ä–æ–∫–∞–º–∏ –≤–∏–¥–∞ `–ü–æ–ª–µ: –ó–Ω–∞—á–µ–Ω–∏–µ` (–≤–∫–ª—é—á–∏: `–°—É–¥`, `–ò—Å—Ç–µ—Ü`, `–û—Ç–≤–µ—Ç—á–∏–∫`, `–¶–µ–Ω–∞ –∏—Å–∫–∞` –∏–ª–∏ –∏–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å, `–ì–æ—Å–ø–æ—à–ª–∏–Ω–∞`/—Å–±–æ—Ä, `–î–∞—Ç–∞`, `–ü–æ–¥–ø–∏—Å—å` —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π; –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ ‚Äî `–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã`, `–°–ø–æ—Å–æ–± –ø–æ–¥–∞—á–∏`). –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –ø—Å–µ–≤–¥–æ–≥—Ä–∞—Ñ–∏–∫—É –∏ –æ–±—Ä–∞—Ç–Ω—ã–µ —Å–ª—ç—à–∏.
   ‚Ä¢ –ü–æ—Å–ª–µ —Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤ –¥–æ–±–∞–≤—å –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ `# {–Ω–∞–∑–≤–∞–Ω–∏–µ}`.
   ‚Ä¢ –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –æ—Ñ–æ—Ä–º–ª—è–π –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ `## ‚Ä¶`; –∏—Å–ø–æ–ª—å–∑—É–π –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ `1.`/`1)` –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –ø—É–Ω–∫—Ç–æ–≤ –∏ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ `-`, `*`, `‚Ä¢`, `‚Äî` –¥–ª—è –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤.
   ‚Ä¢ –ò—Ç–æ–≥–æ–≤—ã–µ –±–ª–æ–∫–∏ (–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —á–∞—Å—Ç—å, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –ø–æ–¥–ø–∏—Å—å) –ø–æ–¥–∞–≤–∞–π –∫–∞–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –±–µ–∑ –æ–±—Ä–∞—Ç–Ω—ã—Ö —Å–ª—ç—à–µ–π –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫.
   ‚Ä¢ –î–ª—è —Ä–∞—Å—á—ë—Ç–æ–≤ –∏ —Å–º–µ—Ç –∏—Å–ø–æ–ª—å–∑—É–π Markdown-—Ç–∞–±–ª–∏—Ü—ã (`| –∫–æ–ª–æ–Ω–∫–∞ | –∫–æ–ª–æ–Ω–∫–∞ |`), —á—Ç–æ–±—ã –∏—Ö –º–æ–∂–Ω–æ –±—ã–ª–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤ Word.
4. –ü–µ—Ä–µ–¥ –≤—ã–¥–∞—á–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–∏ —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫—É: –ø–µ—Ä–µ—á–∏—Å–ª–∏ —É—á—Ç—ë–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏/–ø—Ä–æ–±–µ–ª—ã –≤ self_check.
5. –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
{
  "status": "ok" | "need_more_info" | "abort",
  "document_title": "...",
  "document_markdown": "...",
  "self_check": {
    "validated": ["..."],
    "issues": ["..."]
  },
  "follow_up_questions": ["..."]
}
–ï—Å–ª–∏ status = "ok", –ø–æ–ª–µ document_markdown –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç, –≥–æ—Ç–æ–≤—ã–π –∫ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ Word.
""".strip()

DOCUMENT_PLANNER_SYSTEM_PROMPT = DOCUMENT_ASSISTANT_SYSTEM_PROMPT

USER_TEMPLATE = """
{request_heading}
{request}

{mode_instructions}
""".strip()

PLANNER_MODE_INSTRUCTIONS = """
–°—Ñ–æ—Ä–º–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞:
- –ü–æ–ª–µ document_title ‚Äî —Ç–æ—á–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
- –ü–æ–ª–µ need_more_info = true, –µ—Å–ª–∏ —Ç—Ä–µ–±—É—é—Ç—Å—è –æ—Ç–≤–µ—Ç—ã —é—Ä–∏—Å—Ç–∞; false, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
- –ú–∞—Å—Å–∏–≤ questions: —ç–ª–µ–º–µ–Ω—Ç—ã {"id": "...", "text": "...", "purpose": "..."} —Å –ø–æ—è—Å–Ω–µ–Ω–∏–µ–º —Ü–µ–ª–∏ –≤–æ–ø—Ä–æ—Å–∞.
- –ú–∞—Å—Å–∏–≤ context_notes: –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–º–µ—Ç–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ –≤ JSON.
""".strip()

DOCUMENT_GENERATOR_SYSTEM_PROMPT = DOCUMENT_ASSISTANT_SYSTEM_PROMPT

GENERATOR_MODE_INSTRUCTIONS = """
–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {title}

–û—Ç–≤–µ—Ç—ã —é—Ä–∏—Å—Ç–∞:
{answers}

–°–æ–±–µ—Ä–∏ –∏—Ç–æ–≥ –ø–æ —Å—Ö–µ–º–µ JSON:
{
  "status": "ok" | "need_more_info" | "abort",
  "document_title": "...",
  "document_markdown": "...",
  "self_check": {
    "validated": ["..."],
    "issues": ["..."]
  },
  "follow_up_questions": ["..."]
}
""".strip()


# ================================ Regexes =====================================

_JSON_START_RE = re.compile(r"[{\[]")
_TRAILING_COMMA_RE = re.compile(r",(\s*[}\]])")
_JSON_DECODER = json.JSONDecoder()
_INLINE_MARKUP_RE = re.compile(r"(\*\*.+?\*\*|__.+?__|\*.+?\*|_.+?_|`.+?`)", re.DOTALL)
_BULLET_ITEM_RE = re.compile(r"^([-*‚Ä¢‚Äî‚Äì])\s+(.*)")
_NUMBERED_ITEM_RE = re.compile(r"^\d+[.)]\s+(.*)")
_METADATA_LINE_RE = re.compile(r"^([^:]{1,80}):\s+(.+)$")
_TABLE_SEPARATOR_RE = re.compile(r":?-{3,}:?")


# =============================== JSON helpers =================================

def _strip_code_fences(payload: str) -> str:
    stripped = payload.strip()
    lowered = stripped.lower()
    for prefix in ("```json", "```", "~~~json", "~~~"):
        if lowered.startswith(prefix):
            stripped = stripped[len(prefix):]
            stripped = stripped.lstrip("\r\n")
            break

    for suffix in ("```", "~~~"):
        if stripped.endswith(suffix):
            stripped = stripped[:-len(suffix)]
            stripped = stripped.rstrip()
            break

    return stripped.strip()


def _escape_unescaped_newlines(payload: str) -> str:
    """Escape literal newlines that appear inside JSON strings."""
    if "\n" not in payload and "\r" not in payload:
        return payload

    result: list[str] = []
    in_string = False
    escaped = False
    index = 0
    length = len(payload)

    while index < length:
        char = payload[index]

        if in_string:
            if escaped:
                result.append(char)
                escaped = False
            else:
                if char == "\\":
                    result.append(char)
                    escaped = True
                elif char == '"':
                    result.append(char)
                    in_string = False
                elif char == "\r":
                    result.append("\\r")
                    if index + 1 < length and payload[index + 1] == "\n":
                        result.append("\\n")
                        index += 1
                elif char == "\n":
                    result.append("\\n")
                else:
                    result.append(char)
        else:
            result.append(char)
            if char == '"':
                in_string = True
                escaped = False

        index += 1

    repaired = "".join(result)
    return repaired


def _extract_structured_payload(raw: Any) -> Mapping[str, Any] | None:
    """Attempt to locate the actual JSON payload within structured response metadata."""

    def _unwrap(candidate: Any) -> Mapping[str, Any] | None:
        if isinstance(candidate, Mapping):
            lower_keys = {str(key).lower() for key in candidate.keys()}
            if (
                "document_title" in lower_keys
                or "document_markdown" in lower_keys
                or "status" in lower_keys
                or "questions" in lower_keys
                or "context_notes" in lower_keys
            ):
                return dict(candidate)
            for key in ("parsed", "data", "json_schema"):
                nested = candidate.get(key)
                unwrapped = _unwrap(nested)
                if unwrapped is not None:
                    return unwrapped
            return None

        if isinstance(candidate, (list, tuple)):
            for item in candidate:
                unwrapped = _unwrap(item)
                if unwrapped is not None:
                    return unwrapped
        return None

    return _unwrap(raw)


def _extract_json(text: Any) -> Any:
    """Extract the first JSON structure found in text."""
    if isinstance(text, (dict, list)):
        return text
    if text is None:
        raise DocumentDraftingError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏")
    if not isinstance(text, str):
        raise DocumentDraftingError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏")

    cleaned_text = _strip_code_fences(text)

    def _decode_from_index(source: str, start_index: int = 0) -> Any:
        idx = start_index
        length = len(source)
        while idx < length and source[idx].isspace():
            idx += 1
        if idx >= length:
            raise json.JSONDecodeError("Empty JSON candidate", source, idx)
        try:
            obj, _ = _JSON_DECODER.raw_decode(source, idx)
            return obj
        except (json.JSONDecodeError, ValueError) as primary_err:
            candidate = source[idx:]
            stripped_candidate = candidate.strip()
            if not stripped_candidate:
                raise json.JSONDecodeError("Empty JSON candidate", source, idx) from primary_err

            normalized = _TRAILING_COMMA_RE.sub(r"\1", stripped_candidate)
            attempts = [normalized]

            repaired = _escape_unescaped_newlines(normalized)
            if repaired != normalized:
                attempts.append(repaired)

            for attempt in attempts:
                with suppress(json.JSONDecodeError, ValueError):
                    obj, _ = _JSON_DECODER.raw_decode(attempt)
                    return obj

            raise primary_err

    try:
        return _decode_from_index(cleaned_text)
    except (json.JSONDecodeError, ValueError) as err:
        logger.debug("Primary JSON parse failed, scanning for nested JSON: %s", err)
        for match in _JSON_START_RE.finditer(cleaned_text):
            start_idx = match.start()
            try:
                return _decode_from_index(cleaned_text, start_idx)
            except (json.JSONDecodeError, ValueError):
                continue

    raise DocumentDraftingError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏")


def _format_answers(answers: Iterable[dict[str, str]]) -> str:
    lines = []
    for idx, item in enumerate(answers, 1):
        question = item.get("question", "").strip()
        answer = item.get("answer", "").strip()
        lines.append(f"{idx}. {question}\n   –û—Ç–≤–µ—Ç: {answer}")
    return "\n".join(lines) if lines else "(–û—Ç–≤–µ—Ç—ã –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã)"


# ============================ High-level API calls ============================

async def plan_document(openai_service, request_text: str) -> DraftPlan:
    if not request_text.strip():
        raise DocumentDraftingError("–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å")

    user_prompt = USER_TEMPLATE.format(
        request_heading="–ó–∞–ø—Ä–æ—Å —é—Ä–∏—Å—Ç–∞:",
        request=request_text.strip(),
        mode_instructions=PLANNER_MODE_INSTRUCTIONS,
    )
    response = await openai_service.ask_legal(
        system_prompt=DOCUMENT_ASSISTANT_SYSTEM_PROMPT,
        user_text=user_prompt,
    )
    if not response.get("ok"):
        raise DocumentDraftingError(response.get("error") or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")

    structured = _extract_structured_payload(response.get("structured"))
    if structured:
        logger.debug("Using structured planner payload (keys: %s)", list(structured.keys()))
        data = dict(structured)
    else:
        raw_text = response.get("text", "")
        if not raw_text:
            raise DocumentDraftingError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏")
        data = _extract_json(raw_text)

    title = str(data.get("document_title") or "–î–æ–∫—É–º–µ–Ω—Ç").strip()
    notes = [str(note).strip() for note in data.get("context_notes") or [] if str(note).strip()]

    need_more_raw = data.get("need_more_info")
    if isinstance(need_more_raw, bool):
        need_more = need_more_raw
    elif isinstance(need_more_raw, str):
        lowered = need_more_raw.strip().lower()
        need_more = lowered in {"true", "yes", "1", "y", "–¥–∞"}
    elif need_more_raw is None:
        need_more = False
    else:
        need_more = bool(need_more_raw)

    questions: list[dict[str, str]] = []
    if need_more:
        raw_questions = data.get("questions") or []
        for idx, raw in enumerate(raw_questions):
            text = str(raw.get("text") or "").strip()
            if not text:
                continue
            purpose = str(raw.get("purpose") or "").strip()
            question_id = str(raw.get("id") or f"q{idx + 1}")
            questions.append({"id": question_id, "text": text, "purpose": purpose})

    return DraftPlan(title=title or "–î–æ–∫—É–º–µ–Ω—Ç", questions=questions, notes=notes)


async def generate_document(
    openai_service,
    request_text: str,
    title: str,
    answers: list[dict[str, str]],
) -> DraftResult:
    answers_formatted = _format_answers(answers)
    mode_instructions = GENERATOR_MODE_INSTRUCTIONS.format(
        title=title,
        answers=answers_formatted or "(–û—Ç–≤–µ—Ç—ã –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã)",
    )
    user_prompt = USER_TEMPLATE.format(
        request_heading="–ó–∞–ø—Ä–æ—Å —é—Ä–∏—Å—Ç–∞ –∏ –≤–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:",
        request=request_text.strip(),
        mode_instructions=mode_instructions,
    )
    response = await openai_service.ask_legal(
        system_prompt=DOCUMENT_ASSISTANT_SYSTEM_PROMPT,
        user_text=user_prompt,
    )
    if not response.get("ok"):
        raise DocumentDraftingError(response.get("error") or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")

    structured = _extract_structured_payload(response.get("structured"))
    if structured:
        logger.debug("Using structured generator payload (keys: %s)", list(structured.keys()))
        data = dict(structured)
    else:
        raw_text = response.get("text", "")
        if not raw_text:
            raise DocumentDraftingError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏")
        data = _extract_json(raw_text)

    status = str(data.get("status") or "ok").lower()
    doc_title = str(data.get("document_title") or title).strip()
    markdown = str(data.get("document_markdown") or "")
    self_check = data.get("self_check") or {}
    validated = [str(item).strip() for item in self_check.get("validated") or [] if str(item).strip()]
    issues = [str(item).strip() for item in self_check.get("issues") or [] if str(item).strip()]
    follow_up = [str(item).strip() for item in data.get("follow_up_questions") or [] if str(item).strip()]

    return DraftResult(
        status=status,
        title=doc_title or title,
        markdown=markdown,
        validated=validated,
        issues=issues,
        follow_up_questions=follow_up,
    )


# ============================= DOCX builder (MD) ==============================

def build_docx_from_markdown(markdown: str, output_path: str) -> None:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π Markdown –≤ DOCX, –ø—Ä–∏–º–µ–Ω—è—è –±–∞–∑–æ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —é—Ä–¥–æ–∫–∞–º:
    - –ë—É–º–∞–≥–∞ A4, –ø–æ–ª—è 2.5 —Å–º, —à—Ä–∏—Ñ—Ç Times New Roman 12 pt, –º–µ–∂–¥—É—Å—Ç—Ä–æ—á–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª 1.5
    - –ó–∞–≥–æ–ª–æ–≤–∫–∏ —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å—Ç–∏–ª–∏, –±–µ–∑ –ø—Å–µ–≤–¥–æ–≥—Ä–∞—Ñ–∏–∫–∏
    - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ "–ü–æ–ª–µ: –ó–Ω–∞—á–µ–Ω–∏–µ" ‚Äî –∞–≤—Ç–æ–º–∞—Ç–æ–º —Å–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –≤ 2‚Äë–∫–æ–ª–æ–Ω–æ—á–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–ø–∏—Å–∫–æ–≤ (-, *, ‚Ä¢, ‚Äî) –∏ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ (1. / 1))
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Markdown‚Äë—Ç–∞–±–ª–∏—Ü
    - –ù—É–º–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü ¬´–°—Ç—Ä. X –∏–∑ Y¬ª –≤ –Ω–∏–∂–Ω–µ–º –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–µ
    """
    try:
        from docx import Document  # type: ignore
        from docx.enum.text import WD_ALIGN_PARAGRAPH  # type: ignore
        from docx.oxml import OxmlElement  # type: ignore
        from docx.oxml.ns import qn  # type: ignore
        from docx.shared import Cm, Pt  # type: ignore
    except ImportError as exc:  # pragma: no cover
        raise DocumentDraftingError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å DOCX –±–µ–∑ –ø–∞–∫–µ—Ç–∞ python-docx") from exc

    if not markdown or not markdown.strip():
        raise DocumentDraftingError("–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞")

    document = Document()
    section = document.sections[0]

    # –§–æ—Ä–º–∞—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –ø–æ–ª—è (A4 + 2.5 —Å–º)
    with suppress(Exception):
        section.page_width = Cm(21)
        section.page_height = Cm(29.7)
    for attr in ("top_margin", "bottom_margin", "left_margin", "right_margin"):
        setattr(section, attr, Cm(2.5))

    # ‚Äî‚Äî‚Äî —à—Ä–∏—Ñ—Ç—ã –∏ —Å—Ç–∏–ª–∏
    def _ensure_font(style_name: str, *, size: int, bold: bool = False,
                     italic: bool = False, align: int | None = None) -> None:
        try:
            style = document.styles[style_name]
        except KeyError:
            return
        font = style.font
        font.name = "Times New Roman"
        font.size = Pt(size)
        font.bold = bold
        font.italic = italic
        # –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        if style.element.rPr is not None:
            r_fonts = style.element.rPr.rFonts
            if r_fonts is not None:
                r_fonts.set(qn("w:eastAsia"), "Times New Roman")
        paragraph_format = getattr(style, "paragraph_format", None)
        if paragraph_format:
            paragraph_format.space_after = Pt(6)
            if align is not None:
                paragraph_format.alignment = align

    # Normal
    normal_style = document.styles["Normal"]
    normal_font = normal_style.font
    normal_font.name = "Times New Roman"
    normal_font.size = Pt(12)
    if normal_style.element.rPr is not None:
        r_fonts = normal_style.element.rPr.rFonts
        if r_fonts is not None:
            r_fonts.set(qn("w:eastAsia"), "Times New Roman")
    normal_paragraph = normal_style.paragraph_format
    normal_paragraph.space_after = Pt(6)
    normal_paragraph.first_line_indent = Cm(0)
    normal_paragraph.line_spacing = 1.5

    _ensure_font("Title", size=16, bold=True, align=WD_ALIGN_PARAGRAPH.CENTER)
    _ensure_font("Heading 1", size=14, bold=True)
    _ensure_font("Heading 2", size=13, bold=True)
    _ensure_font("Heading 3", size=12, bold=True)

    # ‚Äî‚Äî‚Äî –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª: "–°—Ç—Ä. X –∏–∑ Y"
    def _add_field(paragraph, instruction: str) -> None:
        run = paragraph.add_run()
        fld_begin = OxmlElement("w:fldChar")
        fld_begin.set(qn("w:fldCharType"), "begin")
        instr = OxmlElement("w:instrText")
        instr.set(qn("xml:space"), "preserve")
        instr.text = instruction
        fld_separate = OxmlElement("w:fldChar")
        fld_separate.set(qn("w:fldCharType"), "separate")
        fld_end = OxmlElement("w:fldChar")
        fld_end.set(qn("w:fldCharType"), "end")
        run._r.append(fld_begin)
        run._r.append(instr)
        run._r.append(fld_separate)
        run._r.append(fld_end)

    with suppress(Exception):
        footer = section.footer
        para = footer.paragraphs[0] if footer.paragraphs else footer.add_paragraph()
        para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        para.paragraph_format.space_before = Pt(0)
        para.paragraph_format.space_after = Pt(0)
        para.add_run("–°—Ç—Ä. ")
        _add_field(para, "PAGE")
        para.add_run(" –∏–∑ ")
        _add_field(para, "NUMPAGES")

    # ‚Äî‚Äî‚Äî inline —Ä–∞–∑–º–µ—Ç–∫–∞
    def _add_runs(paragraph, text: str) -> None:
        for chunk in _INLINE_MARKUP_RE.split(text):
            if not chunk:
                continue
            run = paragraph.add_run()
            if chunk.startswith(("**", "__")) and chunk.endswith(chunk[:2]):
                run.text = chunk[2:-2]
                run.bold = True
            elif chunk.startswith(("*", "_")) and chunk.endswith(chunk[0]):
                run.text = chunk[1:-1]
                run.italic = True
            elif chunk.startswith("`") and chunk.endswith("`"):
                run.text = chunk[1:-1]
                run.font.name = "Consolas"
                run.font.size = Pt(11)
            else:
                run.text = chunk

    # ‚Äî‚Äî‚Äî meta‚Äë–±–ª–æ–∫ —à–∞–ø–∫–∏
    list_mode: str | None = None
    metadata_buffer: list[tuple[str, str]] = []

    def _is_table_row(text: str) -> bool:
        stripped = text.strip()
        return stripped.startswith("|") and stripped.endswith("|") and stripped.count("|") >= 2

    def _parse_table_row(text: str) -> list[str]:
        cells = [cell.strip() for cell in text.strip()[1:-1].split("|")]
        return cells

    def flush_metadata(force_plain: bool = False) -> None:
        nonlocal metadata_buffer
        if not metadata_buffer:
            return

        if not force_plain and len(metadata_buffer) >= 2:
            table = document.add_table(rows=0, cols=2)
            with suppress(Exception):
                table.style = "Table Grid"
            for field, value in metadata_buffer:
                row = table.add_row()
                field_cell, value_cell = row.cells

                fp = field_cell.paragraphs[0]
                fp.paragraph_format.space_before = Pt(0)
                fp.paragraph_format.space_after = Pt(0)
                fp.paragraph_format.first_line_indent = Cm(0)
                fp.alignment = WD_ALIGN_PARAGRAPH.LEFT
                fr = fp.add_run(field)
                fr.bold = True

                vp = value_cell.paragraphs[0]
                vp.paragraph_format.space_before = Pt(0)
                vp.paragraph_format.space_after = Pt(0)
                vp.paragraph_format.first_line_indent = Cm(0)
                vp.alignment = WD_ALIGN_PARAGRAPH.LEFT
                _add_runs(vp, value)

            document.add_paragraph("")  # —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        else:
            for field, value in metadata_buffer:
                paragraph = document.add_paragraph(style="Normal")
                paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
                paragraph.paragraph_format.first_line_indent = Cm(0)
                paragraph.paragraph_format.left_indent = Cm(0)
                paragraph.paragraph_format.space_after = Pt(6)
                _add_runs(paragraph, f"{field}: {value}")

        metadata_buffer = []

    # ‚Äî‚Äî‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–∑–±–æ—Ä Markdown
    lines = markdown.replace("\r\n", "\n").replace("\r", "\n").splitlines()
    idx = 0
    total_lines = len(lines)

    while idx < total_lines:
        raw_line = lines[idx]
        idx += 1
        line = raw_line.rstrip()

        # –ø–æ–¥–¥–µ—Ä–∂–∫–∞ "–∂—ë—Å—Ç–∫–æ–≥–æ –ø–µ—Ä–µ–Ω–æ—Å–∞" –≤ Markdown (backslash –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏)
        if line.endswith("\\"):
            line = line[:-1].rstrip()

        if not line:
            flush_metadata()
            document.add_paragraph("")
            list_mode = None
            continue

        plain_line = line.strip()
        plain_lower = plain_line.lower()

        # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è "–ò—Å–∫–æ–≤–æ–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ ..." –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ ‚Äî –∫–∞–∫ —Ç–∏—Ç—É–ª
        if plain_line and plain_lower.startswith("–∏—Å–∫–æ–≤–æ–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ"):
            title_paragraph = document.add_paragraph(style="Title")
            title_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            title_paragraph.paragraph_format.space_before = Pt(12)
            title_paragraph.paragraph_format.space_after = Pt(12)
            title_paragraph.paragraph_format.keep_with_next = True
            _add_runs(title_paragraph, plain_line)
            list_mode = None
            continue

        # —Å–±–æ—Ä –º–µ—Ç–∞‚Äë—Å—Ç—Ä–æ–∫ "–ü–æ–ª–µ: –ó–Ω–∞—á–µ–Ω–∏–µ" –¥–æ –ø–µ—Ä–≤–æ–≥–æ "–æ–±—ã—á–Ω–æ–≥–æ" –∞–±–∑–∞—Ü–∞/–∑–∞–≥–æ–ª–æ–≤–∫–∞/—Å–ø–∏—Å–∫–∞
        if list_mode is None and plain_line:
            if not plain_line.startswith(("-", "*", "‚Ä¢", "‚Äî", "#")) and not _NUMBERED_ITEM_RE.match(plain_line):
                colon_match = _METADATA_LINE_RE.match(plain_line)
                if colon_match:
                    field = colon_match.group(1).strip()
                    value = colon_match.group(2).strip()
                    if value:
                        metadata_buffer.append((field, value))
                        continue

        # —Ç–∞–±–ª–∏—Ü–∞ –≤ Markdown
        if _is_table_row(line):
            flush_metadata()
            table_lines = [line]
            while idx < total_lines:
                peek_line = lines[idx].rstrip()
                if _is_table_row(peek_line):
                    table_lines.append(peek_line)
                    idx += 1
                else:
                    break

            parsed_rows = [_parse_table_row(row) for row in table_lines]
            # –≤—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å?
            if len(parsed_rows) >= 2 and all(_TABLE_SEPARATOR_RE.fullmatch(cell.replace(" ", "")) for cell in parsed_rows[1]):
                data_rows = [parsed_rows[0]] + parsed_rows[2:]
            else:
                data_rows = parsed_rows

            if data_rows:
                num_cols = max(len(row) for row in data_rows)
                table = document.add_table(rows=0, cols=num_cols)
                with suppress(Exception):
                    table.style = "Table Grid"
                for row_idx, cells in enumerate(data_rows):
                    row = table.add_row()
                    for col in range(num_cols):
                        cell_text = cells[col].strip() if col < len(cells) else ""
                        cell = row.cells[col]
                        paragraph = cell.paragraphs[0]
                        paragraph.paragraph_format.space_before = Pt(0)
                        paragraph.paragraph_format.space_after = Pt(0)
                        paragraph.paragraph_format.first_line_indent = Cm(0)
                        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER if row_idx == 0 else WD_ALIGN_PARAGRAPH.LEFT
                        _add_runs(paragraph, cell_text)
                        if row_idx == 0:
                            for run in paragraph.runs:
                                run.bold = True
                document.add_paragraph("")
            list_mode = None
            continue

        flush_metadata()

        # –∑–∞–≥–æ–ª–æ–≤–∫–∏
        if line.startswith("# "):
            content = line[2:].strip()
            title_paragraph = document.add_paragraph(style="Title")
            title_paragraph.paragraph_format.space_after = Pt(12)
            title_paragraph.paragraph_format.keep_with_next = True
            title_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            _add_runs(title_paragraph, content)  # –±–µ–∑ –Ω–∞—Å–∏–ª—å–Ω–æ–≥–æ UPPERCASE ‚Äî —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Å—Ç–∏–ª—å
            list_mode = None
            continue

        if line.startswith("## "):
            content = line[3:].strip()
            paragraph = document.add_paragraph(style="Heading 1")
            paragraph.paragraph_format.keep_with_next = True
            paragraph.paragraph_format.space_before = Pt(12)
            _add_runs(paragraph, content)
            list_mode = None
            continue

        if line.startswith("### "):
            content = line[4:].strip()
            paragraph = document.add_paragraph(style="Heading 2")
            paragraph.paragraph_format.keep_with_next = True
            paragraph.paragraph_format.space_before = Pt(10)
            _add_runs(paragraph, content)
            list_mode = None
            continue

        # —Å–ø–∏—Å–∫–∏
        bullet_match = _BULLET_ITEM_RE.match(line)
        number_match = _NUMBERED_ITEM_RE.match(line)
        if bullet_match:
            paragraph = document.add_paragraph(style="List Bullet")
            paragraph.paragraph_format.first_line_indent = Pt(0)
            paragraph.paragraph_format.left_indent = Cm(0.75)
            _add_runs(paragraph, bullet_match.group(2).strip())
            list_mode = "bullet"
            continue
        if number_match:
            paragraph = document.add_paragraph(style="List Number")
            paragraph.paragraph_format.first_line_indent = Pt(0)
            paragraph.paragraph_format.left_indent = Cm(0.75)
            _add_runs(paragraph, number_match.group(1).strip())
            list_mode = "number"
            continue

        # –æ–±—ã—á–Ω—ã–µ –∞–±–∑–∞—Ü—ã
        paragraph = document.add_paragraph(style="Normal")
        paragraph.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
        paragraph.paragraph_format.space_after = Pt(6)
        if list_mode:
            paragraph.paragraph_format.left_indent = Cm(1.25)
            paragraph.paragraph_format.first_line_indent = Cm(0)
        else:
            # —Å—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞ "–ü–æ–ª–µ: –∑–Ω–∞—á–µ–Ω–∏–µ" ‚Äî –±–µ–∑ –∫—Ä–∞—Å–Ω–æ–π —Å—Ç—Ä–æ–∫–∏, —Å–ª–µ–≤–∞
            if ":" in plain_line and not plain_line.endswith(":"):
                paragraph.paragraph_format.first_line_indent = Cm(0)
                paragraph.paragraph_format.left_indent = Cm(0)
                paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT
            else:
                paragraph.paragraph_format.first_line_indent = Cm(1.25)
        _add_runs(paragraph, plain_line)
        list_mode = None

    flush_metadata()

    document.save(output_path)


# ================================ UI helpers ==================================

def _pluralize_questions(count: int) -> str:
    """–°–∫–ª–æ–Ω–µ–Ω–∏–µ —Å–ª–æ–≤–∞ '–≤–æ–ø—Ä–æ—Å' –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —á–∏—Å–ª–∞."""
    if count % 10 == 1 and count % 100 != 11:
        return "–≤–æ–ø—Ä–æ—Å"
    elif count % 10 in (2, 3, 4) and count % 100 not in (12, 13, 14):
        return "–≤–æ–ø—Ä–æ—Å–∞"
    else:
        return "–≤–æ–ø—Ä–æ—Å–æ–≤"


def format_plan_summary(plan: DraftPlan) -> str:
    from html import escape as html_escape

    lines: list[str] = []

    title = (plan.title or "–î–æ–∫—É–º–µ–Ω—Ç").strip()
    title_escaped = html_escape(title)

    # –ö—Ä–∞—Å–∏–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    lines.append("üìã <b>–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞</b>")
    lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
    lines.append("")
    lines.append(f"<b>–î–æ–∫—É–º–µ–Ω—Ç:</b> {title_escaped}")
    lines.append("")

    if plan.questions:
        lines.append(f"<b>–¢—Ä–µ–±—É–µ—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:</b> {len(plan.questions)} {_pluralize_questions(len(plan.questions))}")
        lines.append("")
        lines.append("")
        lines.append("üí° <b>–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –æ—Ç–≤–µ—Ç—É</b>")
        lines.append("")
        lines.append("<b>–ö–∞–∫ –æ—Ç–≤–µ—á–∞—Ç—å:</b>")
        lines.append("")
        lines.append("  ‚úì –ù–∞–ø–∏—à–∏—Ç–µ –≤—Å–µ –æ—Ç–≤–µ—Ç—ã –≤ –æ–¥–Ω–æ–º")
        lines.append("    —Å–æ–æ–±—â–µ–Ω–∏–∏, –Ω–µ —Ä–∞–∑–¥–µ–ª—è—è –∏—Ö")
        lines.append("")
        lines.append("<b>–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–æ–≤:</b>")
        lines.append("")
        lines.append("  <b>–í–∞—Ä–∏–∞–Ω—Ç 1</b> ‚Äî –Ω—É–º–µ—Ä–∞—Ü–∏—è:")
        lines.append("  <code>1) –í–∞—à –ø–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç</code>")
        lines.append("  <code>2) –í–∞—à –≤—Ç–æ—Ä–æ–π –æ—Ç–≤–µ—Ç</code>")
        lines.append("  <code>3) –í–∞—à —Ç—Ä–µ—Ç–∏–π –æ—Ç–≤–µ—Ç</code>")
        lines.append("")
        lines.append("  <b>–í–∞—Ä–∏–∞–Ω—Ç 2</b> ‚Äî –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞:")
        lines.append("  <code>–ü–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç</code>")
        lines.append("  <code></code>")
        lines.append("  <code>–í—Ç–æ—Ä–æ–π –æ—Ç–≤–µ—Ç</code>")
        lines.append("")
        lines.append("")
        lines.append("üëá <i>–í–æ–ø—Ä–æ—Å—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –æ—Ç–¥–µ–ª—å–Ω—ã–º</i>")
        lines.append("   <i>—Å–æ–æ–±—â–µ–Ω–∏–µ–º –Ω–∏–∂–µ</i>")
    else:
        lines.append("<b>–°—Ç–∞—Ç—É—Å:</b> –ì–æ—Ç–æ–≤ –∫ —Å–æ–∑–¥–∞–Ω–∏—é ‚úÖ")
        lines.append("")
        lines.append("")
        lines.append("‚úÖ <b>–í—Å—ë –≥–æ—Ç–æ–≤–æ!</b>")
        lines.append("")
        lines.append("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        lines.append("–Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        lines.append("")
        lines.append("üöÄ –ú–æ–∂–Ω–æ –ø—Ä–∏—Å—Ç—É–ø–∞—Ç—å –∫")
        lines.append("   —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞")

    return "\n".join(lines)
