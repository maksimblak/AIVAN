"""Utilities for interactive legal document drafting."""

from __future__ import annotations

import json
import logging
import re
from dataclasses import dataclass
from typing import Any, Iterable

logger = logging.getLogger(__name__)


class DocumentDraftingError(RuntimeError):
    """Raised when the LLM response cannot be processed."""


@dataclass(slots=True)
class DraftPlan:
    title: str
    questions: list[dict[str, str]]
    notes: list[str]


@dataclass(slots=True)
class DraftResult:
    status: str
    title: str
    markdown: str
    validated: list[str]
    issues: list[str]
    follow_up_questions: list[str]


DOCUMENT_PLANNER_SYSTEM_PROMPT = """
–¢—ã ‚Äî —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —é—Ä–∏—Å—Ç—É –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–æ—á–Ω—ã–π –ø—Ä–∞–≤–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–µ–ª–æ.
–†–∞–±–æ—Ç–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ —ç—Ç–∞–ø–∞–º:

1. –ï—Å–ª–∏ —é—Ä–∏—Å—Ç —É–∂–µ –Ω–∞–∑–≤–∞–ª —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ ‚Äî –Ω–∞–π–¥–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –æ–±—Ä–∞–∑–µ—Ü –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ï—Å–ª–∏ —Ç–∏–ø –Ω–µ –æ—á–µ–≤–∏–¥–µ–Ω, –∑–∞–¥–∞–π –Ω–∞–≤–æ–¥—è—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã, —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç –Ω—É–∂–µ–Ω.
2. –ü–æ–¥–≥–æ—Ç–æ–≤—å –ø–µ—Ä–µ—á–µ–Ω—å –≤–æ–ø—Ä–æ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å —é—Ä–∏—Å—Ç—É –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≥—Ä—É–ø–ø–∏—Ä—É–π –∏—Ö –ø–æ —ç—Ç–∞–ø–∞–º –∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ—è—Å–Ω—è–π —Ü–µ–ª—å –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.
3. –°—Ñ–æ—Ä–º–∏—Ä—É–π –∑–∞–º–µ—Ç–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (context_notes), –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≥–æ–¥—è—Ç—Å—è –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –ø–æ–º–æ–≥—É—Ç –ò–ò –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞—Ç—å—Å—è —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.

–í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–π –≤–∞–ª–∏–¥–Ω—ã–π JSON.
""".strip()

DOCUMENT_PLANNER_USER_TEMPLATE = """
–ó–∞–ø—Ä–æ—Å —é—Ä–∏—Å—Ç–∞:
{request}

–°—Ñ–æ—Ä–º–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞:
- –ü–æ–ª–µ document_title ‚Äî —Ç–æ—á–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
- –ü–æ–ª–µ need_more_info = true, –µ—Å–ª–∏ —Ç—Ä–µ–±—É—é—Ç—Å—è –æ—Ç–≤–µ—Ç—ã —é—Ä–∏—Å—Ç–∞; false, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
- –ú–∞—Å—Å–∏–≤ questions: —ç–ª–µ–º–µ–Ω—Ç—ã {{"id": "...", "text": "...", "purpose": "..."}} —Å –ø–æ—è—Å–Ω–µ–Ω–∏–µ–º —Ü–µ–ª–∏ –≤–æ–ø—Ä–æ—Å–∞.
- –ú–∞—Å—Å–∏–≤ context_notes: –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–º–µ—Ç–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ –≤ JSON.
""".strip()

DOCUMENT_GENERATOR_SYSTEM_PROMPT = """
–¢—ã ‚Äî —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–¥–æ–∫—É–º–µ–Ω—Ç–∞–ª–∏—Å—Ç. –ù–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–æ–≤ —é—Ä–∏—Å—Ç–∞ –ø–æ–¥–≥–æ—Ç–æ–≤—å —é—Ä–∏–¥–∏—á–µ—Å–∫–∏ —Ç–æ—á–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç.
–°–ª–µ–¥—É–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:

1. –ü—Ä–æ–≤–µ—Ä—å, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–∞–Ω–Ω—ã—Ö. –ï—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç, –≤–µ—Ä–Ω–∏ status = "need_more_info" –∏ —Å—Ñ–æ—Ä–º–∏—Ä—É–π follow_up_questions —Å —É—Ç–æ—á–Ω–µ–Ω–∏—è–º–∏.
2. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Å–æ—Å—Ç–∞–≤—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ Markdown, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã–π –æ–±—Ä–∞–∑–µ—Ü –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã. –°–æ–±–ª—é–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Å—Ç–∏–ª—å –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –≤–∏–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
3. –ü–µ—Ä–µ–¥ –≤—ã–¥–∞—á–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–∏ —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫—É: –ø–µ—Ä–µ—á–∏—Å–ª–∏ —É—á—Ç—ë–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –≤—ã—è–≤–ª–µ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏/–ø—Ä–æ–±–µ–ª—ã.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ ‚Äî –≤–∞–ª–∏–¥–Ω—ã–π JSON –≤–∏–¥–∞:
{
  "status": "ok" | "need_more_info" | "abort",
  "document_title": "...",
  "document_markdown": "...",
  "self_check": {
    "validated": ["..."],
    "issues": ["..."]
  },
  "follow_up_questions": ["..."]
}
–ï—Å–ª–∏ status = "ok", –ø–æ–ª–µ document_markdown –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç, –≥–æ—Ç–æ–≤—ã–π –∫ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ Word.
""".strip()

DOCUMENT_GENERATOR_USER_TEMPLATE = """
–ó–∞–ø—Ä–æ—Å —é—Ä–∏—Å—Ç–∞ –∏ –≤–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:
{request}

–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {title}

–û—Ç–≤–µ—Ç—ã —é—Ä–∏—Å—Ç–∞:
{answers}

–°–æ–±–µ—Ä–∏ –∏—Ç–æ–≥ –ø–æ —Å—Ö–µ–º–µ JSON:
{{
  "status": "ok" | "need_more_info" | "abort",
  "document_title": "...",
  "document_markdown": "...",
  "self_check": {{
    "validated": ["..."],
    "issues": ["..."]
  }},
  "follow_up_questions": ["..."]
}}
""".strip()

_JSON_START_RE = re.compile(r"[{\[]")
_TRAILING_COMMA_RE = re.compile(r",(\s*[}\]])")
_JSON_DECODER = json.JSONDecoder()


def _strip_code_fences(payload: str) -> str:
    stripped = payload.strip()
    lowered = stripped.lower()
    for prefix in ("```json", "```", "~~~json", "~~~"):
        if lowered.startswith(prefix):
            stripped = stripped[len(prefix) :]
            stripped = stripped.lstrip("\r\n")
            break

    for suffix in ("```", "~~~"):
        if stripped.endswith(suffix):
            stripped = stripped[: -len(suffix)]
            stripped = stripped.rstrip()
            break

    return stripped.strip()


def _extract_json(text: Any) -> Any:
    """Extract the first JSON structure found in text."""

    if isinstance(text, (dict, list)):
        return text
    if text is None:
        raise DocumentDraftingError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏")
    if not isinstance(text, str):
        raise DocumentDraftingError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏")

    cleaned_text = _strip_code_fences(text)

    def _try_parse(candidate: str) -> Any:
        candidate = candidate.strip()
        if not candidate:
            raise json.JSONDecodeError("Empty JSON candidate", candidate, 0)
        normalized = _TRAILING_COMMA_RE.sub(r"\1", candidate)
        obj, _ = _JSON_DECODER.raw_decode(normalized)
        return obj

    try:
        return _try_parse(cleaned_text)
    except (json.JSONDecodeError, ValueError) as err:
        logger.debug("Primary JSON parse failed, scanning for nested JSON: %s", err)
        for match in _JSON_START_RE.finditer(cleaned_text):
            start_idx = match.start()
            try:
                return _try_parse(cleaned_text[start_idx:])
            except (json.JSONDecodeError, ValueError):
                continue

    raise DocumentDraftingError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏")


def _format_answers(answers: Iterable[dict[str, str]]) -> str:
    lines = []
    for idx, item in enumerate(answers, 1):
        question = item.get("question", "").strip()
        answer = item.get("answer", "").strip()
        lines.append(f"{idx}. {question}\n   –û—Ç–≤–µ—Ç: {answer}")
    return "\n".join(lines) if lines else "(–û—Ç–≤–µ—Ç—ã –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã)"



async def plan_document(openai_service, request_text: str) -> DraftPlan:
    if not request_text.strip():
        raise DocumentDraftingError("–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å")

    user_prompt = DOCUMENT_PLANNER_USER_TEMPLATE.format(request=request_text.strip())
    response = await openai_service.ask_legal(
        system_prompt=DOCUMENT_PLANNER_SYSTEM_PROMPT,
        user_text=user_prompt,
    )
    if not response.get("ok"):
        raise DocumentDraftingError(response.get("error") or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")

    raw_text = response.get("text", "")
    if not raw_text:
        raise DocumentDraftingError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏")

    data = _extract_json(raw_text)
    title = str(data.get("document_title") or "–î–æ–∫—É–º–µ–Ω—Ç").strip()
    questions = [
        {
            "id": str(q.get("id") or f"q{i+1}"),
            "text": str(q.get("text") or "").strip(),
            "purpose": str(q.get("purpose") or "").strip(),
        }
        for i, q in enumerate(data.get("questions") or [])
        if str(q.get("text") or "").strip()
    ]
    notes = [str(note).strip() for note in data.get("context_notes") or [] if str(note).strip()]

    need_more = bool(data.get("need_more_info"))
    if not need_more:
        questions = []

    return DraftPlan(title=title or "–î–æ–∫—É–º–µ–Ω—Ç", questions=questions, notes=notes)


async def generate_document(
    openai_service,
    request_text: str,
    title: str,
    answers: list[dict[str, str]],
) -> DraftResult:
    answers_formatted = _format_answers(answers)
    user_prompt = DOCUMENT_GENERATOR_USER_TEMPLATE.format(
        request=request_text.strip(),
        title=title,
        answers=answers_formatted or "(–û—Ç–≤–µ—Ç—ã –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã)",
    )
    response = await openai_service.ask_legal(
        system_prompt=DOCUMENT_GENERATOR_SYSTEM_PROMPT,
        user_text=user_prompt,
    )
    if not response.get("ok"):
        raise DocumentDraftingError(response.get("error") or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")

    raw_text = response.get("text", "")
    if not raw_text:
        raise DocumentDraftingError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏")

    data = _extract_json(raw_text)
    status = str(data.get("status") or "ok").lower()
    doc_title = str(data.get("document_title") or title).strip()
    markdown = str(data.get("document_markdown") or "")
    self_check = data.get("self_check") or {}
    validated = [str(item).strip() for item in self_check.get("validated") or [] if str(item).strip()]
    issues = [str(item).strip() for item in self_check.get("issues") or [] if str(item).strip()]
    follow_up = [str(item).strip() for item in data.get("follow_up_questions") or [] if str(item).strip()]

    return DraftResult(
        status=status,
        title=doc_title or title,
        markdown=markdown,
        validated=validated,
        issues=issues,
        follow_up_questions=follow_up,
    )


def build_docx_from_markdown(markdown: str, output_path: str) -> None:
    try:
        from docx import Document  # type: ignore
        from docx.enum.text import WD_ALIGN_PARAGRAPH  # type: ignore
        from docx.oxml.ns import qn  # type: ignore
        from docx.shared import Cm, Pt  # type: ignore
    except ImportError as exc:  # pragma: no cover
        raise DocumentDraftingError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å DOCX –±–µ–∑ –ø–∞–∫–µ—Ç–∞ python-docx") from exc

    if not markdown.strip():
        raise DocumentDraftingError("–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞")

    document = Document()
    section = document.sections[0]
    for attr in ("top_margin", "bottom_margin", "left_margin", "right_margin"):
        setattr(section, attr, Cm(2.5))

    def _ensure_font(style_name: str, *, size: int, bold: bool = False, italic: bool = False, align: int | None = None) -> None:
        try:
            style = document.styles[style_name]
        except KeyError:
            return
        font = style.font
        font.name = "Times New Roman"
        font.size = Pt(size)
        font.bold = bold
        font.italic = italic
        if style.element.rPr is not None:
            r_fonts = style.element.rPr.rFonts
            if r_fonts is not None:
                r_fonts.set(qn("w:eastAsia"), "Times New Roman")
        paragraph_format = getattr(style, "paragraph_format", None)
        if paragraph_format:
            paragraph_format.space_after = Pt(6)
            if align is not None:
                paragraph_format.alignment = align

    normal_style = document.styles["Normal"]
    normal_font = normal_style.font
    normal_font.name = "Times New Roman"
    normal_font.size = Pt(12)
    if normal_style.element.rPr is not None:
        r_fonts = normal_style.element.rPr.rFonts
        if r_fonts is not None:
            r_fonts.set(qn("w:eastAsia"), "Times New Roman")
    normal_paragraph = normal_style.paragraph_format
    normal_paragraph.space_after = Pt(6)
    normal_paragraph.first_line_indent = Cm(1.25)
    normal_paragraph.line_spacing = 1.5

    _ensure_font("Title", size=16, bold=True, align=WD_ALIGN_PARAGRAPH.CENTER)
    _ensure_font("Heading 1", size=14, bold=True)
    _ensure_font("Heading 2", size=13, bold=True)
    _ensure_font("Heading 3", size=12, bold=True)

    def _add_runs(paragraph, text: str) -> None:
        pattern = re.compile(r"(\*\*.+?\*\*|__.+?__|\*.+?\*|_.+?_|`.+?`)", re.DOTALL)
        for chunk in pattern.split(text):
            if not chunk:
                continue
            run = paragraph.add_run()
            if chunk.startswith(("**", "__")) and chunk.endswith(chunk[:2]):
                run.text = chunk[2:-2]
                run.bold = True
            elif chunk.startswith(("*", "_")) and chunk.endswith(chunk[0]):
                run.text = chunk[1:-1]
                run.italic = True
            elif chunk.startswith("`") and chunk.endswith("`"):
                run.text = chunk[1:-1]
                run.font.name = "Consolas"
                run.font.size = Pt(11)
            else:
                run.text = chunk

    list_mode: str | None = None

    for raw_line in markdown.splitlines():
        line = raw_line.rstrip()

        if not line:
            document.add_paragraph("")
            list_mode = None
            continue

        if line.startswith("# "):
            content = line[2:].strip()
            title_paragraph = document.add_paragraph(style="Title")
            title_paragraph.paragraph_format.space_after = Pt(12)
            title_paragraph.paragraph_format.keep_with_next = True
            title_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            _add_runs(title_paragraph, content.upper())
            list_mode = None
            continue

        if line.startswith("## "):
            content = line[3:].strip()
            paragraph = document.add_paragraph(style="Heading 1")
            paragraph.paragraph_format.keep_with_next = True
            paragraph.paragraph_format.space_before = Pt(12)
            _add_runs(paragraph, content)
            list_mode = None
            continue

        if line.startswith("### "):
            content = line[4:].strip()
            paragraph = document.add_paragraph(style="Heading 2")
            paragraph.paragraph_format.keep_with_next = True
            paragraph.paragraph_format.space_before = Pt(10)
            _add_runs(paragraph, content)
            list_mode = None
            continue

        bullet_match = re.match(r"^[-*]\s+(.*)", line)
        number_match = re.match(r"^\d+[.)]\s+(.*)", line)
        if bullet_match:
            paragraph = document.add_paragraph(style="List Bullet")
            paragraph.paragraph_format.first_line_indent = Pt(0)
            paragraph.paragraph_format.left_indent = Cm(0.75)
            _add_runs(paragraph, bullet_match.group(1).strip())
            list_mode = "bullet"
            continue
        if number_match:
            paragraph = document.add_paragraph(style="List Number")
            paragraph.paragraph_format.first_line_indent = Pt(0)
            paragraph.paragraph_format.left_indent = Cm(0.75)
            _add_runs(paragraph, number_match.group(1).strip())
            list_mode = "number"
            continue

        paragraph = document.add_paragraph(style="Normal")
        paragraph.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
        if list_mode:
            paragraph.paragraph_format.first_line_indent = Cm(1.25)
        _add_runs(paragraph, line.strip())
        list_mode = None

    document.save(output_path)


def format_plan_summary(plan: DraftPlan) -> str:
    lines: list[str] = []

    title = (plan.title or "–î–æ–∫—É–º–µ–Ω—Ç").strip()

    # –ö—Ä–∞—Å–∏–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    lines.append("‚ú® <b>–î–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ —Å–æ–∑–¥–∞–Ω–∏—é</b>")
    lines.append(f"<code>{'‚îÅ' * 35}</code>")
    lines.append("")
    lines.append(f"üìÑ <b>{title}</b>")
    lines.append(f"<code>{'‚îÄ' * 35}</code>")
    lines.append("")

    # Context notes are kept internal, not displayed to users
    # if plan.notes:
    #     lines.append("üîç –ö–æ–Ω—Ç–µ–∫—Å—Ç (–≤–∞–∂–Ω–æ–µ):")
    #     max_notes = 6
    #     for note in plan.notes[:max_notes]:
    #         clean = str(note).strip()
    #         if clean:
    #             lines.append(f"‚Ä¢ {clean}")
    #     remaining = len(plan.notes) - max_notes
    #     if remaining > 0:
    #         lines.append(f"‚Ä¶ –µ—â—ë {remaining} –ø—É–Ω–∫—Ç(–æ–≤)")
    #     lines.append("")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–æ–ø—Ä–æ—Å–∞—Ö
    lines.append(f"‚ùì <b>–£—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:</b> {len(plan.questions)}")

    if plan.questions:
        lines.append("")
        lines.append(f"<code>{'‚îÅ' * 35}</code>")
        lines.append("")
        lines.append("üí° <b>–ö–∞–∫ –æ—Ç–≤–µ—á–∞—Ç—å:</b>")
        lines.append("‚úÖ –ù–∞–ø–∏—à–∏—Ç–µ –≤—Å–µ –æ—Ç–≤–µ—Ç—ã <b>–æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º</b>")
        lines.append("")
        lines.append("<b>–í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è:</b>")
        lines.append("  <code>1) –ü–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç</code>")
        lines.append("  <code>2) –í—Ç–æ—Ä–æ–π –æ—Ç–≤–µ—Ç</code>")
        lines.append("  <i>–∏–ª–∏ —Ä–∞–∑–¥–µ–ª—è–π—Ç–µ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π</i>")
        lines.append("")
        lines.append(f"<code>{'‚îÅ' * 35}</code>")
        lines.append("")
        lines.append("üëá <i>–í–æ–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º</i>")
    else:
        lines.append("")
        lines.append(f"<code>{'‚îÅ' * 35}</code>")
        lines.append("")
        lines.append("‚úÖ <b>–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É—Ç–æ—á–Ω–µ–Ω–∏–π –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è</b>")
        lines.append("üöÄ –ú–æ–∂–Ω–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç")

    return "\n".join(lines)
