from __future__ import annotations

import re
from typing import Iterable, Sequence

from telegram.helpers import escape_markdown

TG_MAX_LEN = 4096

_url_re = re.compile(r"https?://\S+", re.IGNORECASE)


def md2(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ–¥ Telegram MarkdownV2."""
    return escape_markdown(text, version=2)


def format_laws(laws: Iterable[str] | None) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ—Ä–º/—Å—Å—ã–ª–æ–∫:
    - –ù–∞–∑–≤–∞–Ω–∏–µ/–Ω–æ–º–µ—Ä –Ω–æ—Ä–º—ã –¥–∞—ë–º –º–æ–Ω–æ—à–∏—Ä–∏–Ω–Ω–æ
    - URL —Ä–µ–Ω–¥–µ—Ä–∏–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π (–∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–π) —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ —Ç–∏—Ä–µ
    –ü—Ä–∏–º–µ—Ä: ‚Ä¢ `—Å—Ç. 10 –ì–ö –†–§` ‚Äî https://.../article/10
    """
    if not laws:
        return "–ù–æ—Ä–º—ã –ø—Ä–∞–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."

    lines: list[str] = []
    for raw in laws:
        if not raw:
            continue
        raw = raw.strip()
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç URL ‚Äî –æ—Ç–¥–µ–ª—è–µ–º –ø–æ–¥–ø–∏—Å—å –∏ —Å—Å—ã–ª–∫—É
        m = _url_re.search(raw)
        if m:
            url = m.group(0)
            label = raw.replace(url, "").strip(" -‚Äî:") or "–ù–æ—Ä–º–∞"
            lines.append(f"‚Ä¢ `{md2(label)}` ‚Äî {url}")
        else:
            lines.append(f"‚Ä¢ `{md2(raw)}`")
    return "\n".join(lines)


def build_legal_reply(summary: str, details: str, laws: Sequence[str] | None) -> str:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –∫—Ä–∞—Å–∏–≤—ã–π –æ—Ç–≤–µ—Ç –≤ MarkdownV2 –ø–æ —Ç—Ä–µ–±—É–µ–º–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ.
    """
    return (
        f"‚öñÔ∏è *{md2('–Æ–†–ò–î–ò–ß–ï–°–ö–ê–Ø –ö–û–ù–°–£–õ–¨–¢–ê–¶–ò–Ø')}*\n\n"
        f"üìã *{md2('–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç:')}*\n"
        f"{md2(summary)}\n\n"
        f"üìÑ *{md2('–ü–æ–¥—Ä–æ–±–Ω–æ–µ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏–µ:')}*\n"
        f"{md2(details)}\n\n"
        f"üìö *{md2('–ü—Ä–∏–º–µ–Ω–∏–º—ã–µ –Ω–æ—Ä–º—ã –ø—Ä–∞–≤–∞:')}*\n"
        f"{format_laws(laws)}\n\n"
        f"‚ö†Ô∏è *{md2('–í–∞–∂–Ω–æ:')}*\n"
        f"{md2('–î–∞–Ω–Ω–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –Ω–æ—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ –Ω–µ –∑–∞–º–µ–Ω—è–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –ø–æ–º–æ—â—å.')}"
    )


def chunk_markdown_v2(text: str, limit: int = TG_MAX_LEN) -> list[str]:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Ä–µ–∂–µ–º –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è Telegram.
    –ü—Ä–∞–≤–∏–ª–∞:
      1) –ü—ã—Ç–∞–µ–º—Å—è —Ä–µ–∑–∞—Ç—å –ø–æ –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–Ω–æ—Å–∞–º.
      2) –ï—Å–ª–∏ –±–ª–æ–∫ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π ‚Äî –¥–æ—Ä–µ–∑–∞–µ–º –ø–æ –æ–¥–∏–Ω–æ—á–Ω—ã–º –ø–µ—Ä–µ–Ω–æ—Å–∞–º.
      3) –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ ‚Äî –ø—Ä–æ—Å—Ç–æ –ø–æ —Å–∏–º–≤–æ–ª–∞–º.
    """
    parts: list[str] = []
    for block in text.split("\n\n"):
        block = block.strip()
        if not block:
            continue
        if len(block) <= limit:
            parts.append(block)
            continue

        # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
        cur = block
        while len(cur) > limit:
            cut = cur.rfind("\n", 0, limit)
            if cut == -1:
                cut = limit
            parts.append(cur[:cut])
            cur = cur[cut:].lstrip()
        if cur:
            parts.append(cur)
    return parts
