from __future__ import annotations

import asyncio
import logging
import time
from collections import defaultdict, deque
from dataclasses import dataclass, field
from typing import Deque, Dict, Optional

from aiogram import Router, types, F
from aiogram.enums import ChatAction, ParseMode

from telegram_legal_bot.config import Settings, load_settings
from telegram_legal_bot.services.openai_service import OpenAIService, LegalAdvice
from telegram_legal_bot.utils.message_formatter import build_legal_reply, chunk_markdown_v2

logger = logging.getLogger(__name__)
router = Router()

# --------- –ø—Ä–æ—Å—Ç–µ–π—à–∏–π per-user rate limit (in-memory, 1h –æ–∫–Ω–æ) ----------
@dataclass
class RateWindow:
    timestamps: Deque[float] = field(default_factory=deque)

    def hit(self, now: float, max_per_hour: int) -> bool:
        hour_ago = now - 3600.0
        while self.timestamps and self.timestamps[0] < hour_ago:
            self.timestamps.popleft()
        if len(self.timestamps) >= max_per_hour:
            return False
        self.timestamps.append(now)
        return True

_rate_map: Dict[int, RateWindow] = defaultdict(RateWindow)
_history: Dict[int, Deque[str]] = defaultdict(lambda: deque(maxlen=5))

# DI –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä-–ø–æ–¥–æ–±–Ω–æ: –ø–æ–ª–æ–∂–∏–º —Å–µ—Ä–≤–∏—Å—ã –≤ "context" —Ä–æ—É—Ç–µ—Ä–∞
def setup_context(router: Router, settings: Settings, ai: OpenAIService) -> None:
    router.data["settings"] = settings
    router.data["ai"] = ai


def _looks_like_spam(text: str) -> bool:
    t = text.replace(" ", "")
    if len(t) > 20:
        from collections import Counter
        c = Counter(t)
        if c.most_common(1)[0][1] / len(t) > 0.6:
            return True
    words = [w for w in text.lower().split() if w]
    rep = 1
    for i in range(1, len(words)):
        if words[i] == words[i - 1]:
            rep += 1
            if rep >= 6:
                return True
        else:
            rep = 1
    return False


@router.message(F.text & ~F.text.startswith("/"))
async def handle_legal_query(message: types.Message, event_chat: types.Chat) -> None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –±–µ–∑ –∫–æ–º–∞–Ω–¥:
      - –≤–∞–ª–∏–¥–∞—Ü–∏—è
      - rate-limit
      - –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–µ—á–∞—Ç–∏
      - –∑–∞–ø—Ä–æ—Å –∫ GPT-5
      - —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–∞–Ω–∫–∞–º–∏
    """
    settings: Settings = router.data["settings"]
    ai: OpenAIService = router.data["ai"]

    text = (message.text or "").strip()
    if len(text) < settings.min_question_length:
        await message.answer(
            f"üßê –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ–¥—Ä–æ–±–Ω–µ–µ (–º–∏–Ω–∏–º—É–º {settings.min_question_length} —Å–∏–º–≤–æ–ª–æ–≤)."
        )
        return
    if _looks_like_spam(text):
        await message.answer("ü§ñ –ü–æ—Ö–æ–∂–µ –Ω–∞ —Å–ø–∞–º/—Ñ–ª—É–¥. –ï—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ ‚Äî –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –≤–æ–ø—Ä–æ—Å.")
        return

    user_id = message.from_user.id if message.from_user else 0
    now = time.time()
    if not _rate_map[user_id].hit(now, settings.max_requests_per_hour):
        await message.answer("‚è≥ –õ–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ —á–∞—Å –∏—Å—á–µ—Ä–ø–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return

    # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä "–ø–µ—á–∞—Ç–∞–µ—Ç..."
    try:
        await message.bot.send_chat_action(chat_id=message.chat.id, action=ChatAction.TYPING)
    except Exception:
        pass

    try:
        advice: LegalAdvice = await ai.generate_legal_advice(
            user_question=text, short_history=list(_history[user_id])
        )
    except asyncio.TimeoutError:
        await message.answer("‚è±Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ OpenAI: %s", e)
        await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return

    reply = build_legal_reply(advice.summary, advice.details, advice.laws)
    for i, ch in enumerate(chunk_markdown_v2(reply)):
        prefix = "" if i == 0 else "‚Ä¶–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ:\n\n"
        await message.answer(prefix + ch, parse_mode=ParseMode.MARKDOWN_V2, disable_web_page_preview=True)

    if advice.summary:
        _history[user_id].append(advice.summary)
